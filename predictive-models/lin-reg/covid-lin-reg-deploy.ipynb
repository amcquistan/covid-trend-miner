{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "9a382df1d56c00d93e8afc0859ca513f06a273a4d86d6d00230aa0762a4a733f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "source": [
    "# Grab covid data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join(\n",
    "    os.path.dirname(os.path.abspath('.')),\n",
    "    '.env'\n",
    ")\n",
    "load_dotenv(dotenv_path, verbose=True)\n",
    "conn_string = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "source": [
    "### Grab all covid state data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT f.date_id, f.location_id, cases, recoveries, deaths, \n",
    "    cases_100k, testing_rate, hospitalization_rate,\n",
    "    date, year, month, day_of_week, day_of_month,\n",
    "    country, state, city, latitude, longitude, population\n",
    "FROM covid_facts f JOIN date_dim d ON d.date_id = f.date_id\n",
    "JOIN location_dim l ON l.location_id = f.location_id\n",
    "WHERE country = 'US' AND city IS NULL\n",
    "ORDER BY state\n",
    "\"\"\"\n",
    "\n",
    "us_df = pd.read_sql(sql, engine)"
   ]
  },
  {
   "source": [
    "### Remove rows with null population"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = us_df.loc[pd.notnull(us_df.population)]"
   ]
  },
  {
   "source": [
    "# Add region information for each state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.read_csv('https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = states_df.rename(columns=lambda col: col.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us2_df = us_df.join(states_df.set_index('state'), on='state').sort_values(['state', 'date'])"
   ]
  },
  {
   "source": [
    "# Preprocess data\n",
    "### Normalize case, recoveries, and deaths using the population"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "us2_df['cases_norm100k'] = us2_df.cases / (us2_df.population / 100_000)\n",
    "us2_df['recoveries_norm100k'] = us2_df.recoveries / (us2_df.population / 100_000)\n",
    "us2_df['deaths_norm100k'] = us2_df.deaths / (us2_df.population / 100_000)\n"
   ]
  },
  {
   "source": [
    "### Seperate region per column and remove columns that are not needed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "us3_df = pd.get_dummies(us2_df, columns = ['region'])\n",
    "us3_df = us3_df.drop(['year','month','state code', 'day_of_week', 'longitude', 'division', 'location_id', 'day_of_month', 'city', 'latitude'], axis = 1)"
   ]
  },
  {
   "source": [
    "#Define a function that takes each row of states and combines them to one region row."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df, group_fields):\n",
    "    grouped = df.groupby(group_fields)\n",
    "    flattened_df = pd.DataFrame()\n",
    "    for name, group in grouped:\n",
    "        row = {}\n",
    "        row['name'] = name\n",
    "        row['cases'] = group.cases.sum()\n",
    "        row['testing_rate'] = group.testing_rate.mean()\n",
    "        row['cases_norm100k'] = group.cases_norm100k.sum()\n",
    "        row['recoveries_norm100k'] = group.recoveries_norm100k.sum()\n",
    "        row['deaths_norm100k'] = group.deaths_norm100k.sum()\n",
    "        for state in group.state.values:\n",
    "            state_data =  group[group.state == state]\n",
    "            row[state+'_cases_norm100k'] = state_data.cases_norm100k.values[0]\n",
    "            row[state+'_recoveries_norm100k'] = state_data.recoveries_norm100k.values[0]\n",
    "            row[state+'_deaths_norm100k'] = state_data.deaths_norm100k.values[0]\n",
    "            row[state+'_testing_rate'] = state_data.testing_rate.values[0]\n",
    "        flattened_df = flattened_df.append(row, ignore_index = True)\n",
    "    return flattened_df"
   ]
  },
  {
   "source": [
    "# Data preperation: Getting the feature set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creates a sliding window that takes 15 days worth of information and creates features based on the 15 days of data.\n",
    "### returns: \n",
    "    X which is the features/predictors\n",
    "    y which is the actual cases 7 days into the future\n",
    "    date which holds cases for the current date"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, segment_time_frame, days_out):\n",
    "    X = pd.DataFrame()\n",
    "    y = []\n",
    "    data_df = pd.DataFrame()\n",
    "    loop_count = 0\n",
    "    date = pd.DataFrame()\n",
    "    date['name'] = df['name']\n",
    "    date['cases'] = df['cases']\n",
    "    for index, row in df.drop('name', axis = 1).iterrows():\n",
    "        loop_count = loop_count + 1\n",
    "        data_df = data_df.append(row)\n",
    "        if data_df.shape[0] >= segment_time_frame:\n",
    "            #Calculate Features\n",
    "            features = {}\n",
    "            for column in data_df.columns:\n",
    "                if column != 'cases':\n",
    "                    features['Max_' + column] = data_df[column].max()\n",
    "                    features['Min_' + column] = data_df[column].min()\n",
    "                    features['AVG_' + column] = data_df[column].mean()\n",
    "                    if segment_time_frame > 1:\n",
    "                        features[column + '_2'] = data_df[column].values[-1] - data_df[column].values[-2]\n",
    "                        if segment_time_frame >= 3:\n",
    "                            features[column + '_3'] = data_df[column].values[-1] - data_df[column].values[-3]\n",
    "                            if segment_time_frame >= 5:\n",
    "                                features[column + '_5'] = data_df[column].values[-1] - data_df[column].values[-5]\n",
    "                                if segment_time_frame >= 7:\n",
    "                                    features[column + '_7'] = data_df[column].values[-1] - data_df[column].values[-7]\n",
    "                                    if segment_time_frame >= 8:\n",
    "                                        features[column + '_' + str(segment_time_frame)] = data_df[column].values[-1] - data_df[column].values[-segment_time_frame]\n",
    "            #Append Features\n",
    "            X = X.append(features, ignore_index = True)\n",
    "            data_df = data_df.iloc[1:,:]\n",
    "            try:\n",
    "                y.append(df.cases[index + days_out])\n",
    "            except:\n",
    "                y.append(-1)\n",
    "    return X.iloc[:, :], y[:], date"
   ]
  },
  {
   "source": [
    "## Seperate state by region"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_northeast_df = us3_df[us3_df.region_Northeast == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_south_df = us3_df[us3_df.region_South== 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_midwest_df = us3_df[us3_df.region_Midwest == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_west_df = us3_df[us3_df.region_West == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)"
   ]
  },
  {
   "source": [
    "## Flatten each data frame to get region data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "northeast_flattened_df = flatten_df(us_northeast_df, ['date'])\n",
    "south_flattened_df = flatten_df(us_south_df, ['date'])\n",
    "midwest_flattened_df = flatten_df(us_midwest_df, ['date'])\n",
    "west_flattened_df = flatten_df(us_west_df, ['date'])"
   ]
  },
  {
   "source": [
    "## Get the feature set and fill null values with average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "northeast_X, northeast_y, northeast_date = sliding_window(northeast_flattened_df, 15, 7)\n",
    "northeast_X['Target'] = northeast_y\n",
    "northeast_X = northeast_X.fillna(northeast_X.mean())\n",
    "\n",
    "south_X, south_y, south_date = sliding_window(south_flattened_df, 15, 7)\n",
    "south_X['Target'] = south_y\n",
    "south_X = south_X.fillna(south_X.mean())\n",
    "\n",
    "midwest_X, midwest_y, midwest_date = sliding_window(midwest_flattened_df, 15, 7)\n",
    "midwest_X['Target'] = midwest_y\n",
    "midwest_X = midwest_X.fillna(midwest_X.mean())\n",
    "\n",
    "west_X, west_y, west_date = sliding_window(west_flattened_df, 15, 7)\n",
    "west_X['Target'] = west_y\n",
    "west_X = west_X.fillna(west_X.mean())\n"
   ]
  },
  {
   "source": [
    "## Split into training and prediction set, Reduce columns based on Chi2 and correlation values, and normalize the features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORTHEAST_CHOSEN_COLUMNS = ['AVG_Massachusetts_testing_rate', 'AVG_Rhode Island_testing_rate', 'Connecticut_testing_rate_15', 'Massachusetts_testing_rate_15', 'Max_Rhode Island_testing_rate', 'Min_Rhode Island_testing_rate', 'Min_cases_norm100k', 'Vermont_testing_rate_15', 'cases_norm100k_15', 'testing_rate_15']\n",
    "northeast_train, northeast_pred = northeast_X[northeast_X.Target != -1], northeast_X[northeast_X.Target == -1]\n",
    "northeast_X_train, northeast_X_pred, northeast_y_train, northeast_y_pred = northeast_train.drop('Target', axis = 1), northeast_pred.drop('Target', axis = 1), northeast_train['Target'], northeast_pred['Target']\n",
    "northeast_selected_X_train = northeast_X_train[NORTHEAST_CHOSEN_COLUMNS]\n",
    "northeast_selected_X_pred = northeast_X_pred[NORTHEAST_CHOSEN_COLUMNS]\n",
    "northeast_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(northeast_selected_X_train), columns = northeast_selected_X_train.columns)\n",
    "northeast_transformed_X_pred = pd.DataFrame(Normalizer().transform(northeast_selected_X_pred), columns = northeast_selected_X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOUTH_CHOSEN_COLUMNS = ['Florida_testing_rate_15', 'Kentucky_testing_rate_15', 'Maryland_testing_rate_15', 'Min_District of Columbia_testing_rate', 'Min_cases_norm100k', 'North Carolina_testing_rate_15', 'West Virginia_testing_rate_15', 'cases_norm100k_15']\n",
    "south_train, south_pred = south_X[south_X.Target != -1], south_X[south_X.Target == -1]\n",
    "south_X_train, south_X_pred, south_y_train, south_y_pred = south_train.drop('Target', axis = 1), south_pred.drop('Target', axis = 1), south_train['Target'], south_pred['Target']\n",
    "south_selected_X_train = south_X_train[SOUTH_CHOSEN_COLUMNS]\n",
    "south_selected_X_pred = south_X_pred[SOUTH_CHOSEN_COLUMNS]\n",
    "south_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(south_selected_X_train), columns = south_selected_X_train.columns)\n",
    "south_transformed_X_pred = pd.DataFrame(Normalizer().transform(south_selected_X_pred), columns = south_selected_X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDWEST_CHOSEN_COLUMNS = ['Indiana_testing_rate_15', 'Max_North Dakota_testing_rate', 'Min_Illinois_testing_rate', 'Min_North Dakota_testing_rate', 'Minnesota_testing_rate_15', 'Missouri_testing_rate_15', 'North Dakota_testing_rate_7', 'Ohio_testing_rate_15', 'Wisconsin_testing_rate_15', 'testing_rate_15']\n",
    "midwest_train, midwest_pred = midwest_X[midwest_X.Target != -1], midwest_X[midwest_X.Target == -1]\n",
    "midwest_X_train, midwest_X_pred, midwest_y_train, midwest_y_pred = midwest_train.drop('Target', axis = 1), midwest_pred.drop('Target', axis = 1), midwest_train['Target'], midwest_pred['Target']\n",
    "midwest_selected_X_train = midwest_X_train[MIDWEST_CHOSEN_COLUMNS]\n",
    "midwest_selected_X_pred = midwest_X_pred[MIDWEST_CHOSEN_COLUMNS]\n",
    "midwest_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(midwest_selected_X_train), columns = midwest_selected_X_train.columns)\n",
    "midwest_transformed_X_pred = pd.DataFrame(Normalizer().transform(midwest_selected_X_pred), columns = midwest_selected_X_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEST_CHOSEN_COLUMNS = ['Alaska_testing_rate_15', 'California_testing_rate_15', 'Colorado_testing_rate_15', 'Max_Alaska_testing_rate', 'Max_New Mexico_testing_rate', 'Max_Utah_testing_rate', 'Min_California_testing_rate', 'Montana_testing_rate_15', 'Nevada_testing_rate_15', 'Wyoming_testing_rate_15']\n",
    "west_train, west_pred = west_X[west_X.Target != -1], west_X[west_X.Target == -1]\n",
    "west_X_train, west_X_pred, west_y_train, west_y_pred = west_train.drop('Target', axis = 1), west_pred.drop('Target', axis = 1), west_train['Target'], west_pred['Target']\n",
    "west_selected_X_train = west_X_train[WEST_CHOSEN_COLUMNS]\n",
    "west_selected_X_pred = west_X_pred[WEST_CHOSEN_COLUMNS]\n",
    "west_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(west_selected_X_train), columns = west_selected_X_train.columns)\n",
    "west_transformed_X_pred = pd.DataFrame(Normalizer().transform(west_selected_X_pred), columns = west_selected_X_pred.columns)"
   ]
  },
  {
   "source": [
    "# Create Models and Get Feature Coefficients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'AVG_Massachusetts_testing_rate': 1354822.6836440896, 'AVG_Rhode Island_testing_rate': -289407.7362192827, 'Connecticut_testing_rate_15': -1413016.3729377198, 'Massachusetts_testing_rate_15': -1618632.8972917062, 'Max_Rhode Island_testing_rate': -697769.43944101, 'Min_Rhode Island_testing_rate': -66517.04228042983, 'Min_cases_norm100k': -1876570.8840820524, 'Vermont_testing_rate_15': 495740.70309168106, 'cases_norm100k_15': 1991731.975432865, 'testing_rate_15': -1477686.358171992}\n"
     ]
    }
   ],
   "source": [
    "northeast_reg = linear_model.LinearRegression().fit(northeast_transformed_X_train, northeast_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(northeast_transformed_X_train.columns):\n",
    "    coef[name] = northeast_reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Florida_testing_rate_15': 1528563.8127750708, 'Kentucky_testing_rate_15': 3847387.1023170445, 'Maryland_testing_rate_15': 1330512.5780275983, 'Min_District of Columbia_testing_rate': 15277477.752419276, 'Min_cases_norm100k': -7683948.55711173, 'North Carolina_testing_rate_15': -8284364.23326627, 'West Virginia_testing_rate_15': 1128163.8728087465, 'cases_norm100k_15': 2503863.434444497}\n"
     ]
    }
   ],
   "source": [
    "south_reg = linear_model.LinearRegression().fit(south_transformed_X_train, south_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(south_transformed_X_train.columns):\n",
    "    coef[name] = south_reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Indiana_testing_rate_15': -156207.2864877961, 'Max_North Dakota_testing_rate': -10914076.690230891, 'Min_Illinois_testing_rate': -6638046.633458029, 'Min_North Dakota_testing_rate': -3659119.0108886114, 'Minnesota_testing_rate_15': -3532713.745818762, 'Missouri_testing_rate_15': -10729519.373115787, 'North Dakota_testing_rate_7': -4007128.108816498, 'Ohio_testing_rate_15': -24151673.259564348, 'Wisconsin_testing_rate_15': -696199.4672842445, 'testing_rate_15': 2557791.6290436666}\n"
     ]
    }
   ],
   "source": [
    "midwest_reg = linear_model.LinearRegression().fit(midwest_transformed_X_train, midwest_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(midwest_transformed_X_train.columns):\n",
    "    coef[name] = midwest_reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Alaska_testing_rate_15': -2459464.311345873, 'California_testing_rate_15': -2844465.7315095873, 'Colorado_testing_rate_15': -929936.3925986027, 'Max_Alaska_testing_rate': 5292496.959012461, 'Max_New Mexico_testing_rate': -4282144.657340931, 'Max_Utah_testing_rate': -606961.4417109918, 'Min_California_testing_rate': -3378932.3902869658, 'Montana_testing_rate_15': 2110240.5852365135, 'Nevada_testing_rate_15': 2513296.956759238, 'Wyoming_testing_rate_15': 1034017.2607235867}\n"
     ]
    }
   ],
   "source": [
    "west_reg = linear_model.LinearRegression().fit(west_transformed_X_train, west_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(west_transformed_X_train.columns):\n",
    "    coef[name] = west_reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "source": [
    "# Get model predictions using the pred data and print out some model performance measures explained on Adam's blog\n",
    "ref https://stackabuse.com/using-machine-learning-to-predict-the-weather-part-2/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.00\nThe Mean Absolute Error: 1491425.41 cases\nThe Median Absolute Error: 1491807.80 cases\n[1485598.75058569 1489838.47951334 1496269.07135185 1491806.79927414\n 1493571.31473748 1496471.96568086 1486414.49884509]\n"
     ]
    }
   ],
   "source": [
    "northeast_prediction = northeast_reg.predict(northeast_transformed_X_pred)\n",
    "print(\"The Explained Variance: %.2f\" % northeast_reg.score(northeast_transformed_X_pred, northeast_y_pred))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(northeast_y_pred, northeast_prediction))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(northeast_y_pred, northeast_prediction))\n",
    "print(northeast_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.00\nThe Mean Absolute Error: 4500377.69 cases\nThe Median Absolute Error: 4486588.33 cases\n[4452411.51410636 4426249.27488373 4486587.3268437  4525371.32048392\n 4540747.61634873 4478560.13785672 4592709.62670735]\n"
     ]
    }
   ],
   "source": [
    "south_prediction = south_reg.predict(south_transformed_X_pred)\n",
    "print(\"The Explained Variance: %.2f\" % south_reg.score(south_transformed_X_pred, south_y_pred))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(south_y_pred, south_prediction))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(south_y_pred, south_prediction))\n",
    "print(south_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.00\nThe Mean Absolute Error: 2552495.41 cases\nThe Median Absolute Error: 2538630.55 cases\n[2516314.30227803 2518747.24617815 2538629.55495597 2506855.89164359\n 2586885.42015274 2626273.73216125 2573754.71406075]\n"
     ]
    }
   ],
   "source": [
    "midwest_prediction = midwest_reg.predict(midwest_transformed_X_pred)\n",
    "print(\"The Explained Variance: %.2f\" % midwest_reg.score(midwest_transformed_X_pred, midwest_y_pred))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(midwest_y_pred, midwest_prediction))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(midwest_y_pred, midwest_prediction))\n",
    "print(midwest_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.00\nThe Mean Absolute Error: 2590351.98 cases\nThe Median Absolute Error: 2633004.94 cases\n[2622454.76934103 2641555.35210671 2640240.0156282  2633003.94411836\n 2642001.41129701 2471076.35479093 2482125.03671604]\n"
     ]
    }
   ],
   "source": [
    "west_prediction = west_reg.predict(west_transformed_X_pred)\n",
    "print(\"The Explained Variance: %.2f\" % west_reg.score(west_transformed_X_pred, west_y_pred))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(west_y_pred, west_prediction))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(west_y_pred, west_prediction))\n",
    "print(west_prediction)"
   ]
  },
  {
   "source": [
    "# Append Predictions to actual cases and months"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendPredictions(df, predictions):\n",
    "    for value in predictions:\n",
    "        new_day = (df.iloc[-1,0] + pd.Timedelta(days = 1))\n",
    "        series = pd.Series()\n",
    "        series['name'] = new_day\n",
    "        series['cases'] = value\n",
    "        df = df.append(series, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(255, 2)\n(262, 2)\n"
     ]
    }
   ],
   "source": [
    "print(northeast_date.shape)\n",
    "northeast_date_complete = appendPredictions(northeast_date, northeast_prediction)\n",
    "print(northeast_date_complete.shape)\n",
    "south_date_complete = appendPredictions(south_date, south_prediction)\n",
    "midwest_date_complete = appendPredictions(midwest_date, midwest_prediction)\n",
    "west_date_complete = appendPredictions(west_date, west_prediction)\n"
   ]
  },
  {
   "source": [
    "# Create Region Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date  northeast_cases   south_cases  midwest_cases  west_cases\n",
       "252  2020-12-08     2.056180e+06  5.893050e+06      3640667.0   2659078.0\n",
       "253  2020-12-09     2.091064e+06  5.967068e+06      3696722.0   2691771.0\n",
       "254  2020-12-10     2.128356e+06  6.041786e+06      3756122.0   2723408.0\n",
       "255  2020-12-11     1.485599e+06  4.452412e+06      3821649.0   2768534.0\n",
       "256  2020-12-12     1.489838e+06  4.426249e+06      3878913.0   2811724.0\n",
       "257  2020-12-13     1.496269e+06  4.486587e+06      3917000.0   2860139.0\n",
       "258  2020-12-14     1.491807e+06  4.525371e+06      3969831.0   2911305.0\n",
       "259  2020-12-15     1.493571e+06  4.540748e+06      4030940.0   2966201.0\n",
       "260  2020-12-16     1.496472e+06  4.478560e+06      4084569.0   3015589.0\n",
       "261  2020-12-17     1.486414e+06  4.592710e+06      4138167.0   3063466.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>northeast_cases</th>\n      <th>south_cases</th>\n      <th>midwest_cases</th>\n      <th>west_cases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>252</th>\n      <td>2020-12-08</td>\n      <td>2.056180e+06</td>\n      <td>5.893050e+06</td>\n      <td>3640667.0</td>\n      <td>2659078.0</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>2020-12-09</td>\n      <td>2.091064e+06</td>\n      <td>5.967068e+06</td>\n      <td>3696722.0</td>\n      <td>2691771.0</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>2020-12-10</td>\n      <td>2.128356e+06</td>\n      <td>6.041786e+06</td>\n      <td>3756122.0</td>\n      <td>2723408.0</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>2020-12-11</td>\n      <td>1.485599e+06</td>\n      <td>4.452412e+06</td>\n      <td>3821649.0</td>\n      <td>2768534.0</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>2020-12-12</td>\n      <td>1.489838e+06</td>\n      <td>4.426249e+06</td>\n      <td>3878913.0</td>\n      <td>2811724.0</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>2020-12-13</td>\n      <td>1.496269e+06</td>\n      <td>4.486587e+06</td>\n      <td>3917000.0</td>\n      <td>2860139.0</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>2020-12-14</td>\n      <td>1.491807e+06</td>\n      <td>4.525371e+06</td>\n      <td>3969831.0</td>\n      <td>2911305.0</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>2020-12-15</td>\n      <td>1.493571e+06</td>\n      <td>4.540748e+06</td>\n      <td>4030940.0</td>\n      <td>2966201.0</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>2020-12-16</td>\n      <td>1.496472e+06</td>\n      <td>4.478560e+06</td>\n      <td>4084569.0</td>\n      <td>3015589.0</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>2020-12-17</td>\n      <td>1.486414e+06</td>\n      <td>4.592710e+06</td>\n      <td>4138167.0</td>\n      <td>3063466.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "region_df = pd.DataFrame()\n",
    "region_df['date'] = northeast_date_complete.name\n",
    "region_df['northeast_cases'] = northeast_date_complete.cases\n",
    "region_df['south_cases'] = south_date_complete.cases\n",
    "region_df['midwest_cases'] = midwest_date_complete.cases\n",
    "region_df['west_cases'] = west_date_complete.cases\n",
    "region_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}