{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "source": [
    "# Grab covid data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join(\n",
    "    os.path.dirname(os.path.abspath('.')),\n",
    "    '.env'\n",
    ")\n",
    "load_dotenv(dotenv_path, verbose=True)\n",
    "conn_string = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "source": [
    "### Grab all covid state data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT f.date_id, f.location_id, cases, recoveries, deaths, \n",
    "    cases_100k, testing_rate, hospitalization_rate,\n",
    "    date, year, month, day_of_week, day_of_month,\n",
    "    country, state, city, latitude, longitude, population\n",
    "FROM covid_facts f JOIN date_dim d ON d.date_id = f.date_id\n",
    "JOIN location_dim l ON l.location_id = f.location_id\n",
    "WHERE country = 'US' AND city IS NULL\n",
    "ORDER BY state\n",
    "\"\"\"\n",
    "\n",
    "us_df = pd.read_sql(sql, engine)"
   ]
  },
  {
   "source": [
    "### Remove rows with null population"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = us_df.loc[pd.notnull(us_df.population)]"
   ]
  },
  {
   "source": [
    "# Add region information for each state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.read_csv('https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv')\n",
    "states_df = states_df.rename(columns=lambda col: col.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us2_df = us_df.join(states_df.set_index('state'), on='state').sort_values(['state', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_northeast_df = us2_df[us2_df.region == 'Northeast']\n",
    "us_south_df = us2_df[us2_df.region == 'South']\n",
    "us_midwest_df = us2_df[us2_df.region == 'Midwest']\n",
    "us_west_df = us2_df[us2_df.region == 'West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_northeast_df['cases_norm100k'] = us_northeast_df.cases / (us_northeast_df.population / 100_000)\n",
    "us_northeast_df['recoveries_norm100k'] = us_northeast_df.recoveries / (us_northeast_df.population / 100_000)\n",
    "us_northeast_df['deaths_norm100k'] = us_northeast_df.deaths / (us_northeast_df.population / 100_000)\n",
    "us_south_df['cases_norm100k'] = us_south_df.cases / (us_south_df.population / 100_000)\n",
    "us_south_df['recoveries_norm100k'] = us_south_df.recoveries / (us_south_df.population / 100_000)\n",
    "us_south_df['deaths_norm100k'] = us_south_df.deaths / (us_south_df.population / 100_000)\n",
    "us_midwest_df['cases_norm100k'] = us_midwest_df.cases / (us_midwest_df.population / 100_000)\n",
    "us_midwest_df['recoveries_norm100k'] = us_midwest_df.recoveries / (us_midwest_df.population / 100_000)\n",
    "us_midwest_df['deaths_norm100k'] = us_midwest_df.deaths / (us_midwest_df.population / 100_000)\n",
    "us_west_df['cases_norm100k'] = us_west_df.cases / (us_west_df.population / 100_000)\n",
    "us_west_df['recoveries_norm100k'] = us_west_df.recoveries / (us_west_df.population / 100_000)\n",
    "us_west_df['deaths_norm100k'] = us_west_df.deaths / (us_west_df.population / 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      date_id  cases  recoveries  deaths  testing_rate        date  \\\n",
       "1933       49      2         0.0     0.0           NaN  2020-03-10   \n",
       "1858       50      3         0.0     0.0           NaN  2020-03-11   \n",
       "1843       51      5         0.0     0.0           NaN  2020-03-12   \n",
       "1912       52     11         0.0     0.0           NaN  2020-03-13   \n",
       "1993       53     22         0.0     0.0           NaN  2020-03-14   \n",
       "\n",
       "            state  population  cases_norm100k  recoveries_norm100k  \\\n",
       "1933  Connecticut   3565287.0        0.056096                  0.0   \n",
       "1858  Connecticut   3565287.0        0.084145                  0.0   \n",
       "1843  Connecticut   3565287.0        0.140241                  0.0   \n",
       "1912  Connecticut   3565287.0        0.308531                  0.0   \n",
       "1993  Connecticut   3565287.0        0.617061                  0.0   \n",
       "\n",
       "      deaths_norm100k  \n",
       "1933              0.0  \n",
       "1858              0.0  \n",
       "1843              0.0  \n",
       "1912              0.0  \n",
       "1993              0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>cases</th>\n      <th>recoveries</th>\n      <th>deaths</th>\n      <th>testing_rate</th>\n      <th>date</th>\n      <th>state</th>\n      <th>population</th>\n      <th>cases_norm100k</th>\n      <th>recoveries_norm100k</th>\n      <th>deaths_norm100k</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1933</th>\n      <td>49</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2020-03-10</td>\n      <td>Connecticut</td>\n      <td>3565287.0</td>\n      <td>0.056096</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1858</th>\n      <td>50</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2020-03-11</td>\n      <td>Connecticut</td>\n      <td>3565287.0</td>\n      <td>0.084145</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1843</th>\n      <td>51</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2020-03-12</td>\n      <td>Connecticut</td>\n      <td>3565287.0</td>\n      <td>0.140241</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1912</th>\n      <td>52</td>\n      <td>11</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2020-03-13</td>\n      <td>Connecticut</td>\n      <td>3565287.0</td>\n      <td>0.308531</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>53</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2020-03-14</td>\n      <td>Connecticut</td>\n      <td>3565287.0</td>\n      <td>0.617061</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "us3_df = us_northeast_df.append(us_south_df.append(us_midwest_df).append(us_west_df))\n",
    "us3_df = us3_df.drop(['year','month', 'country', 'state code', 'cases_100k', 'day_of_week', 'region', 'hospitalization_rate', 'longitude', 'division', 'location_id', 'day_of_month', 'city', 'latitude'], axis = 1)\n",
    "us3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, segment_time_frame, days_out):\n",
    "    X = pd.DataFrame()\n",
    "    y = []\n",
    "    loop_count = 0\n",
    "    groups = df.groupby('state')\n",
    "    for name, group in groups:\n",
    "        print(name)\n",
    "        data_df = pd.DataFrame()\n",
    "        for index, row in group.sort_values('date').drop(['state','date'], axis = 1).iterrows():\n",
    "            loop_count = loop_count + 1\n",
    "            data_df = data_df.append(row)\n",
    "            if data_df.shape[0] >= segment_time_frame:\n",
    "                #Calculate Features\n",
    "                features = {}\n",
    "                features['state'] = name\n",
    "                features['date'] = group.date[index]\n",
    "                for column in data_df.columns:\n",
    "                    if column not in ['state', 'date']:\n",
    "                        features['Max_' + column] = data_df[column].max()\n",
    "                        features['Min_' + column] = data_df[column].min()\n",
    "                        features['AVG_' + column] = data_df[column].mean()\n",
    "                        if segment_time_frame > 1:\n",
    "                            features[column + '_2'] = data_df[column].values[-1] - data_df[column].values[-2]\n",
    "                            if segment_time_frame >= 3:\n",
    "                                features[column + '_3'] = data_df[column].values[-1] - data_df[column].values[-3]\n",
    "                                if segment_time_frame >= 5:\n",
    "                                    features[column + '_5'] = data_df[column].values[-1] - data_df[column].values[-5]\n",
    "                                    if segment_time_frame >= 7:\n",
    "                                        features[column + '_7'] = data_df[column].values[-1] - data_df[column].values[-7]\n",
    "                                        if segment_time_frame >= 8:\n",
    "                                            features[column + '_' + str(segment_time_frame)] = data_df[column].values[-1] - data_df[column].values[-segment_time_frame]\n",
    "                #Append Features\n",
    "                X = X.append(features, ignore_index = True)\n",
    "                data_df = data_df.iloc[1:,:]\n",
    "                try:\n",
    "                    y.append(group.sort_values('date').cases[index + days_out])\n",
    "                except:\n",
    "                    y.append(-1)\n",
    "    return X.iloc[:, :], y[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alabama\n",
      "Alaska\n",
      "Arizona\n",
      "Arkansas\n",
      "California\n",
      "Colorado\n",
      "Connecticut\n",
      "Delaware\n",
      "District of Columbia\n",
      "Florida\n",
      "Georgia\n",
      "Hawaii\n",
      "Idaho\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Kansas\n",
      "Kentucky\n",
      "Louisiana\n",
      "Maine\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Minnesota\n",
      "Mississippi\n",
      "Missouri\n",
      "Montana\n",
      "Nebraska\n",
      "Nevada\n",
      "New Hampshire\n",
      "New Jersey\n",
      "New Mexico\n",
      "New York\n",
      "North Carolina\n",
      "North Dakota\n",
      "Ohio\n",
      "Oklahoma\n",
      "Oregon\n",
      "Pennsylvania\n",
      "Rhode Island\n",
      "South Carolina\n",
      "South Dakota\n",
      "Tennessee\n",
      "Texas\n",
      "Utah\n",
      "Vermont\n",
      "Virginia\n",
      "Washington\n",
      "West Virginia\n",
      "Wisconsin\n",
      "Wyoming\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[158717, 4041, 230708, 13186, 173002]"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "X, y = sliding_window(us3_df, 15, 7)\n",
    "X.head()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    if X[column].isnull().values.all():\n",
    "        print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2 = X2.drop([''], axis = 1)\n",
    "X2 = X.fillna(X.mean())\n",
    "X2['Target'] = y\n",
    "X_val, X2 = X2[X2['Target'] == -1], X2[X2['Target'] != -1]\n",
    "y_val, X_val, y2, X2 = X_val['Target'], X_val.drop('Target', axis = 1), X2['Target'], X2.drop('Target', axis = 1), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['AVG_cases', 'AVG_cases_norm100k', 'AVG_date_id', 'AVG_deaths', 'AVG_deaths_norm100k', 'AVG_population', 'AVG_recoveries', 'AVG_recoveries_norm100k', 'AVG_testing_rate', 'Max_cases', 'Max_cases_norm100k', 'Max_date_id', 'Max_deaths', 'Max_deaths_norm100k', 'Max_population', 'Max_recoveries', 'Max_recoveries_norm100k', 'Max_testing_rate', 'Min_cases', 'Min_cases_norm100k', 'Min_date_id', 'Min_deaths', 'Min_deaths_norm100k', 'Min_population', 'Min_recoveries', 'Min_recoveries_norm100k', 'Min_testing_rate', 'cases_15', 'cases_2', 'cases_3', 'cases_5', 'cases_7', 'cases_norm100k_15', 'cases_norm100k_2', 'cases_norm100k_3', 'cases_norm100k_5', 'cases_norm100k_7', 'date_id_15', 'date_id_2', 'date_id_3', 'date_id_5', 'date_id_7', 'deaths_15', 'deaths_2', 'deaths_3', 'deaths_5', 'deaths_7', 'deaths_norm100k_15', 'deaths_norm100k_2', 'deaths_norm100k_3', 'deaths_norm100k_5', 'deaths_norm100k_7', 'population_15', 'population_2', 'population_3', 'population_5', 'population_7', 'recoveries_15', 'recoveries_2', 'recoveries_3', 'recoveries_5', 'recoveries_7', 'recoveries_norm100k_15', 'recoveries_norm100k_2', 'recoveries_norm100k_3', 'recoveries_norm100k_5', 'recoveries_norm100k_7', 'testing_rate_15', 'testing_rate_2', 'testing_rate_3', 'testing_rate_5', 'testing_rate_7']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size = .25)\n",
    "print([column for column in X_train.columns if column not in ['date', 'state']])\n",
    "transformed_X_train = pd.DataFrame(Normalizer().fit_transform(X_train[[column for column in X_train.columns if column not in ['date', 'state']]]), columns = [column for column in X_train.columns if column not in ['date', 'state']]) + 1\n",
    "transformed_X_test = pd.DataFrame(Normalizer().transform(X_test[[column for column in X_test.columns if column not in ['date', 'state']]]), columns = [column for column in X_train.columns if column not in ['date', 'state']]) + 1\n",
    "\n",
    "selected_col_idx = SelectKBest(chi2, k = 15).fit(transformed_X_train, y_train).get_support(indices = True)\n",
    "selected_X_train = transformed_X_train.iloc[:, selected_col_idx]\n",
    "selected_X_test = transformed_X_test.iloc[:, selected_col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['AVG_cases', 'AVG_recoveries', 'cases_15', 'recoveries_15',\n       'testing_rate_15'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_selected_X_train = selected_X_train.drop(['testing_rate_3', 'testing_rate_5', 'testing_rate_7', 'Min_testing_rate', 'Max_cases', 'Min_cases', 'Max_recoveries', 'Min_recoveries', 'AVG_testing_rate', 'Max_testing_rate'], axis = 1)\n",
    "new_selected_X_test = selected_X_test.drop(['testing_rate_3', 'testing_rate_5', 'testing_rate_7', 'Min_testing_rate', 'Max_cases', 'Min_cases', 'Max_recoveries', 'Min_recoveries', 'AVG_testing_rate', 'Max_testing_rate'], axis = 1)\n",
    "corr_matrix = new_selected_X_train.corr('spearman')\n",
    "for row_idx, row in corr_matrix.iterrows():\n",
    "    for col_idx, cor in row.iteritems():\n",
    "        if col_idx != row_idx and cor > .8:\n",
    "            print(str(row_idx) + ' ' + str(col_idx) + ' = ' + str(corr_matrix.loc[row_idx, col_idx]))\n",
    "print(new_selected_X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'AVG_cases': 7374229.928063626, 'AVG_recoveries': -6648077.405275628, 'cases_15': -9888702.410170933, 'recoveries_15': 2084840.7868394887, 'testing_rate_15': -9020275.513910199}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression().fit(new_selected_X_train, y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(new_selected_X_train.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.07\nThe Mean Absolute Error: 100090.61 cases\nThe Median Absolute Error: 71785.00 cases\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(new_selected_X_test)\n",
    "print(\"The Explained Variance: %.2f\" % reg.score(new_selected_X_test, y_test))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(y_test, y_pred))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = new_selected_X_train.append(new_selected_X_test)\n",
    "y3 = list(y_train) + list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'AVG_cases': 7374229.928063626, 'AVG_recoveries': -6648077.405275628, 'cases_15': -9888702.410170933, 'recoveries_15': 2084840.7868394887, 'testing_rate_15': -9020275.513910199}\n"
     ]
    }
   ],
   "source": [
    "reg2 = linear_model.LinearRegression().fit(X3, y3)\n",
    "coef = {}\n",
    "for idx, name in enumerate(X3.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      AVG_cases  AVG_recoveries  cases_15  recoveries_15  testing_rate_15  \\\n",
       "4755   1.000199        1.000000  1.000536       1.000834         1.000464   \n",
       "5474   1.000236        1.000000  1.000563       1.000834         1.000464   \n",
       "160    1.000275        1.000000  1.000585       1.000834         1.000464   \n",
       "3212   1.000316        1.000000  1.000605       1.000834         1.000464   \n",
       "6317   1.000358        1.000000  1.000632       1.000834         1.000464   \n",
       "1636   1.000402        1.000000  1.000665       1.000834         1.000464   \n",
       "8102   1.000448        1.000000  1.000685       1.000834         1.000464   \n",
       "2113   1.000496        1.000000  1.000708       1.000834         1.000464   \n",
       "7380   1.000544        1.000000  1.000723       1.000834         1.000464   \n",
       "2005   1.000594        1.004744  1.000331       1.000834         1.000131   \n",
       "6333   1.000617        1.004744  1.000324       1.000834         1.000113   \n",
       "7436   1.000640        1.004744  1.000327       1.000834         1.000107   \n",
       "2461   1.000663        1.004744  1.000315       1.000834         1.000116   \n",
       "2336   1.000686        1.000000  1.000321       1.000834         1.000128   \n",
       "453    1.000709        1.000000  1.000339       1.000834         1.000136   \n",
       "6189   1.000734        1.000000  1.000343       1.000834         1.000125   \n",
       "7914   1.000759        1.000000  1.000353       1.000834         1.000117   \n",
       "1990   1.000784        1.000000  1.000358       1.000834         1.000144   \n",
       "4412   1.000811        1.000000  1.000367       1.000834         1.000146   \n",
       "8418   1.000837        1.000000  1.000362       1.000834         1.000153   \n",
       "3851   1.000864        1.000000  1.000379       1.000834         1.000157   \n",
       "6142   1.000892        1.000000  1.000394       1.000834         1.000169   \n",
       "\n",
       "      Target    state        date  \n",
       "4755  158717  Alabama  2020-04-17  \n",
       "5474    4041  Alabama  2020-04-18  \n",
       "160   230708  Alabama  2020-04-19  \n",
       "3212   13186  Alabama  2020-04-20  \n",
       "6317  173002  Alabama  2020-04-21  \n",
       "1636    8203  Alabama  2020-04-22  \n",
       "8102  190113  Alabama  2020-04-23  \n",
       "2113  138619  Alabama  2020-04-24  \n",
       "7380    7700  Alabama  2020-04-25  \n",
       "2005  168620  Alabama  2020-04-26  \n",
       "6333   70600  Alabama  2020-04-27  \n",
       "7436  141454  Alabama  2020-04-28  \n",
       "2461  139660  Alabama  2020-04-29  \n",
       "2336  276665  Alabama  2020-04-30  \n",
       "453     6621  Alabama  2020-05-01  \n",
       "6189  131690  Alabama  2020-05-02  \n",
       "7914  280187  Alabama  2020-05-03  \n",
       "1990    7440  Alabama  2020-05-04  \n",
       "4412  242874  Alabama  2020-05-05  \n",
       "8418  185938  Alabama  2020-05-06  \n",
       "3851  172137  Alabama  2020-05-07  \n",
       "6142  175210  Alabama  2020-05-08  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AVG_cases</th>\n      <th>AVG_recoveries</th>\n      <th>cases_15</th>\n      <th>recoveries_15</th>\n      <th>testing_rate_15</th>\n      <th>Target</th>\n      <th>state</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4755</th>\n      <td>1.000199</td>\n      <td>1.000000</td>\n      <td>1.000536</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>158717</td>\n      <td>Alabama</td>\n      <td>2020-04-17</td>\n    </tr>\n    <tr>\n      <th>5474</th>\n      <td>1.000236</td>\n      <td>1.000000</td>\n      <td>1.000563</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>4041</td>\n      <td>Alabama</td>\n      <td>2020-04-18</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>1.000275</td>\n      <td>1.000000</td>\n      <td>1.000585</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>230708</td>\n      <td>Alabama</td>\n      <td>2020-04-19</td>\n    </tr>\n    <tr>\n      <th>3212</th>\n      <td>1.000316</td>\n      <td>1.000000</td>\n      <td>1.000605</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>13186</td>\n      <td>Alabama</td>\n      <td>2020-04-20</td>\n    </tr>\n    <tr>\n      <th>6317</th>\n      <td>1.000358</td>\n      <td>1.000000</td>\n      <td>1.000632</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>173002</td>\n      <td>Alabama</td>\n      <td>2020-04-21</td>\n    </tr>\n    <tr>\n      <th>1636</th>\n      <td>1.000402</td>\n      <td>1.000000</td>\n      <td>1.000665</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>8203</td>\n      <td>Alabama</td>\n      <td>2020-04-22</td>\n    </tr>\n    <tr>\n      <th>8102</th>\n      <td>1.000448</td>\n      <td>1.000000</td>\n      <td>1.000685</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>190113</td>\n      <td>Alabama</td>\n      <td>2020-04-23</td>\n    </tr>\n    <tr>\n      <th>2113</th>\n      <td>1.000496</td>\n      <td>1.000000</td>\n      <td>1.000708</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>138619</td>\n      <td>Alabama</td>\n      <td>2020-04-24</td>\n    </tr>\n    <tr>\n      <th>7380</th>\n      <td>1.000544</td>\n      <td>1.000000</td>\n      <td>1.000723</td>\n      <td>1.000834</td>\n      <td>1.000464</td>\n      <td>7700</td>\n      <td>Alabama</td>\n      <td>2020-04-25</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>1.000594</td>\n      <td>1.004744</td>\n      <td>1.000331</td>\n      <td>1.000834</td>\n      <td>1.000131</td>\n      <td>168620</td>\n      <td>Alabama</td>\n      <td>2020-04-26</td>\n    </tr>\n    <tr>\n      <th>6333</th>\n      <td>1.000617</td>\n      <td>1.004744</td>\n      <td>1.000324</td>\n      <td>1.000834</td>\n      <td>1.000113</td>\n      <td>70600</td>\n      <td>Alabama</td>\n      <td>2020-04-27</td>\n    </tr>\n    <tr>\n      <th>7436</th>\n      <td>1.000640</td>\n      <td>1.004744</td>\n      <td>1.000327</td>\n      <td>1.000834</td>\n      <td>1.000107</td>\n      <td>141454</td>\n      <td>Alabama</td>\n      <td>2020-04-28</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>1.000663</td>\n      <td>1.004744</td>\n      <td>1.000315</td>\n      <td>1.000834</td>\n      <td>1.000116</td>\n      <td>139660</td>\n      <td>Alabama</td>\n      <td>2020-04-29</td>\n    </tr>\n    <tr>\n      <th>2336</th>\n      <td>1.000686</td>\n      <td>1.000000</td>\n      <td>1.000321</td>\n      <td>1.000834</td>\n      <td>1.000128</td>\n      <td>276665</td>\n      <td>Alabama</td>\n      <td>2020-04-30</td>\n    </tr>\n    <tr>\n      <th>453</th>\n      <td>1.000709</td>\n      <td>1.000000</td>\n      <td>1.000339</td>\n      <td>1.000834</td>\n      <td>1.000136</td>\n      <td>6621</td>\n      <td>Alabama</td>\n      <td>2020-05-01</td>\n    </tr>\n    <tr>\n      <th>6189</th>\n      <td>1.000734</td>\n      <td>1.000000</td>\n      <td>1.000343</td>\n      <td>1.000834</td>\n      <td>1.000125</td>\n      <td>131690</td>\n      <td>Alabama</td>\n      <td>2020-05-02</td>\n    </tr>\n    <tr>\n      <th>7914</th>\n      <td>1.000759</td>\n      <td>1.000000</td>\n      <td>1.000353</td>\n      <td>1.000834</td>\n      <td>1.000117</td>\n      <td>280187</td>\n      <td>Alabama</td>\n      <td>2020-05-03</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>1.000784</td>\n      <td>1.000000</td>\n      <td>1.000358</td>\n      <td>1.000834</td>\n      <td>1.000144</td>\n      <td>7440</td>\n      <td>Alabama</td>\n      <td>2020-05-04</td>\n    </tr>\n    <tr>\n      <th>4412</th>\n      <td>1.000811</td>\n      <td>1.000000</td>\n      <td>1.000367</td>\n      <td>1.000834</td>\n      <td>1.000146</td>\n      <td>242874</td>\n      <td>Alabama</td>\n      <td>2020-05-05</td>\n    </tr>\n    <tr>\n      <th>8418</th>\n      <td>1.000837</td>\n      <td>1.000000</td>\n      <td>1.000362</td>\n      <td>1.000834</td>\n      <td>1.000153</td>\n      <td>185938</td>\n      <td>Alabama</td>\n      <td>2020-05-06</td>\n    </tr>\n    <tr>\n      <th>3851</th>\n      <td>1.000864</td>\n      <td>1.000000</td>\n      <td>1.000379</td>\n      <td>1.000834</td>\n      <td>1.000157</td>\n      <td>172137</td>\n      <td>Alabama</td>\n      <td>2020-05-07</td>\n    </tr>\n    <tr>\n      <th>6142</th>\n      <td>1.000892</td>\n      <td>1.000000</td>\n      <td>1.000394</td>\n      <td>1.000834</td>\n      <td>1.000169</td>\n      <td>175210</td>\n      <td>Alabama</td>\n      <td>2020-05-08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "final_df = X3.copy()\n",
    "final_df['Target'] = y3\n",
    "final_df['state'] = list(X_train['state'].values) + list(X_test['state'].values)\n",
    "final_df['date'] = list(X_train['date'].values) + list(X_test['date'].values)\n",
    "final_df = final_df.sort_values(by = ['state', 'date'])\n",
    "final_df.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}