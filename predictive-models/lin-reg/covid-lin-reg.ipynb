{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "covid-trend-miner",
   "display_name": "covid-trend-miner",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join(\n",
    "    os.path.dirname(os.path.abspath('.')),\n",
    "    '.env'\n",
    ")\n",
    "load_dotenv(dotenv_path, verbose=True)\n",
    "conn_string = os.getenv('DATABASE_URL')\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT f.date_id, f.location_id, cases, recoveries, deaths, \n",
    "    cases_100k, testing_rate, hospitalization_rate,\n",
    "    date, year, month, day_of_week, day_of_month,\n",
    "    country, state, city, latitude, longitude, population\n",
    "FROM covid_facts f JOIN date_dim d ON d.date_id = f.date_id\n",
    "JOIN location_dim l ON l.location_id = f.location_id\n",
    "WHERE country = 'US' AND city IS NULL\n",
    "ORDER BY state\n",
    "\"\"\"\n",
    "\n",
    "us_df = pd.read_sql(sql, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15161, 19)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   date_id  location_id   cases  recoveries  deaths   cases_100k  \\\n",
       "0      314     84000001  249524    161946.0  3578.0  5089.018668   \n",
       "1      156     84000001   33880     18866.0   896.0   677.233268   \n",
       "2       87     84000001    4557         NaN   148.0    97.485613   \n",
       "3      206     84000001  106096     41523.0  1893.0  2168.162123   \n",
       "4      270     84000001  172137     74238.0  2788.0  3501.030453   \n",
       "\n",
       "   testing_rate  hospitalization_rate        date  year  month  day_of_week  \\\n",
       "0  32312.609049                   NaN  2020-11-30  2020     11            0   \n",
       "1   7535.061394              7.866048  2020-06-25  2020      6            3   \n",
       "2    807.183438             12.994968  2020-04-17  2020      4            4   \n",
       "3  16825.471607             11.716788  2020-08-14  2020      8            4   \n",
       "4  25469.057358                   NaN  2020-10-17  2020     10            5   \n",
       "\n",
       "   day_of_month country    state  city  latitude  longitude  population  \n",
       "0            30      US  Alabama  None   32.3182   -86.9023   4903185.0  \n",
       "1            25      US  Alabama  None   32.3182   -86.9023   4903185.0  \n",
       "2            17      US  Alabama  None   32.3182   -86.9023   4903185.0  \n",
       "3            14      US  Alabama  None   32.3182   -86.9023   4903185.0  \n",
       "4            17      US  Alabama  None   32.3182   -86.9023   4903185.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>location_id</th>\n      <th>cases</th>\n      <th>recoveries</th>\n      <th>deaths</th>\n      <th>cases_100k</th>\n      <th>testing_rate</th>\n      <th>hospitalization_rate</th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>day_of_month</th>\n      <th>country</th>\n      <th>state</th>\n      <th>city</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>314</td>\n      <td>84000001</td>\n      <td>249524</td>\n      <td>161946.0</td>\n      <td>3578.0</td>\n      <td>5089.018668</td>\n      <td>32312.609049</td>\n      <td>NaN</td>\n      <td>2020-11-30</td>\n      <td>2020</td>\n      <td>11</td>\n      <td>0</td>\n      <td>30</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156</td>\n      <td>84000001</td>\n      <td>33880</td>\n      <td>18866.0</td>\n      <td>896.0</td>\n      <td>677.233268</td>\n      <td>7535.061394</td>\n      <td>7.866048</td>\n      <td>2020-06-25</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>3</td>\n      <td>25</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>84000001</td>\n      <td>4557</td>\n      <td>NaN</td>\n      <td>148.0</td>\n      <td>97.485613</td>\n      <td>807.183438</td>\n      <td>12.994968</td>\n      <td>2020-04-17</td>\n      <td>2020</td>\n      <td>4</td>\n      <td>4</td>\n      <td>17</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>206</td>\n      <td>84000001</td>\n      <td>106096</td>\n      <td>41523.0</td>\n      <td>1893.0</td>\n      <td>2168.162123</td>\n      <td>16825.471607</td>\n      <td>11.716788</td>\n      <td>2020-08-14</td>\n      <td>2020</td>\n      <td>8</td>\n      <td>4</td>\n      <td>14</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>270</td>\n      <td>84000001</td>\n      <td>172137</td>\n      <td>74238.0</td>\n      <td>2788.0</td>\n      <td>3501.030453</td>\n      <td>25469.057358</td>\n      <td>NaN</td>\n      <td>2020-10-17</td>\n      <td>2020</td>\n      <td>10</td>\n      <td>5</td>\n      <td>17</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "print(us_df.shape)\n",
    "us_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date_id   location_id         cases    recoveries        deaths  \\\n",
       "count  14347.000000  1.434700e+04  1.434700e+04  1.204200e+04  14318.000000   \n",
       "mean     195.342720  7.628919e+07  9.323985e+04  3.968685e+04   2761.020813   \n",
       "std       75.854579  2.425471e+07  1.625244e+05  8.758581e+04   5215.403780   \n",
       "min        1.000000  1.600000e+01  0.000000e+00  0.000000e+00      0.000000   \n",
       "25%      132.000000  8.400001e+07  5.501500e+03  1.599000e+03    122.000000   \n",
       "50%      196.000000  8.400003e+07  3.151300e+04  8.497000e+03    742.000000   \n",
       "75%      260.000000  8.400004e+07  1.121210e+05  4.224950e+04   3010.750000   \n",
       "max      324.000000  8.400006e+07  1.482551e+06  1.074579e+06  35266.000000   \n",
       "\n",
       "         cases_100k   testing_rate  hospitalization_rate     year  \\\n",
       "count  14347.000000   13608.000000           5129.000000  14347.0   \n",
       "mean    1436.403103   22595.625605             12.143891   2020.0   \n",
       "std     1490.061215   22908.352860              5.245396      0.0   \n",
       "min        0.000000       5.391708              1.418440   2020.0   \n",
       "25%      269.530036    5834.146651              8.359942   2020.0   \n",
       "50%     1002.899136   16100.979569             11.282093   2020.0   \n",
       "75%     2122.452916   30515.969012             15.268243   2020.0   \n",
       "max    11710.000000  159983.423970             38.501190   2020.0   \n",
       "\n",
       "              month   day_of_week  day_of_month      latitude     longitude  \\\n",
       "count  14347.000000  14347.000000  14347.000000  14347.000000  14347.000000   \n",
       "mean       7.592319      2.988151     15.803513     36.800569    -84.994608   \n",
       "std        2.508962      1.994206      8.672605     10.796163     49.684960   \n",
       "min        1.000000      0.000000      1.000000    -14.271000   -170.132000   \n",
       "25%        6.000000      1.000000      8.000000     33.856900   -105.311100   \n",
       "50%        8.000000      3.000000     16.000000     39.059800    -86.902300   \n",
       "75%       10.000000      5.000000     23.000000     42.230200    -76.802100   \n",
       "max       12.000000      6.000000     31.000000     61.370700    145.673900   \n",
       "\n",
       "         population  \n",
       "count  1.434700e+04  \n",
       "mean   6.023471e+06  \n",
       "std    8.981471e+06  \n",
       "min    5.514400e+04  \n",
       "25%    1.344212e+06  \n",
       "50%    3.565287e+06  \n",
       "75%    7.278717e+06  \n",
       "max    3.294663e+08  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>location_id</th>\n      <th>cases</th>\n      <th>recoveries</th>\n      <th>deaths</th>\n      <th>cases_100k</th>\n      <th>testing_rate</th>\n      <th>hospitalization_rate</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>day_of_month</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14347.000000</td>\n      <td>1.434700e+04</td>\n      <td>1.434700e+04</td>\n      <td>1.204200e+04</td>\n      <td>14318.000000</td>\n      <td>14347.000000</td>\n      <td>13608.000000</td>\n      <td>5129.000000</td>\n      <td>14347.0</td>\n      <td>14347.000000</td>\n      <td>14347.000000</td>\n      <td>14347.000000</td>\n      <td>14347.000000</td>\n      <td>14347.000000</td>\n      <td>1.434700e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>195.342720</td>\n      <td>7.628919e+07</td>\n      <td>9.323985e+04</td>\n      <td>3.968685e+04</td>\n      <td>2761.020813</td>\n      <td>1436.403103</td>\n      <td>22595.625605</td>\n      <td>12.143891</td>\n      <td>2020.0</td>\n      <td>7.592319</td>\n      <td>2.988151</td>\n      <td>15.803513</td>\n      <td>36.800569</td>\n      <td>-84.994608</td>\n      <td>6.023471e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>75.854579</td>\n      <td>2.425471e+07</td>\n      <td>1.625244e+05</td>\n      <td>8.758581e+04</td>\n      <td>5215.403780</td>\n      <td>1490.061215</td>\n      <td>22908.352860</td>\n      <td>5.245396</td>\n      <td>0.0</td>\n      <td>2.508962</td>\n      <td>1.994206</td>\n      <td>8.672605</td>\n      <td>10.796163</td>\n      <td>49.684960</td>\n      <td>8.981471e+06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.600000e+01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.391708</td>\n      <td>1.418440</td>\n      <td>2020.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-14.271000</td>\n      <td>-170.132000</td>\n      <td>5.514400e+04</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>132.000000</td>\n      <td>8.400001e+07</td>\n      <td>5.501500e+03</td>\n      <td>1.599000e+03</td>\n      <td>122.000000</td>\n      <td>269.530036</td>\n      <td>5834.146651</td>\n      <td>8.359942</td>\n      <td>2020.0</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n      <td>33.856900</td>\n      <td>-105.311100</td>\n      <td>1.344212e+06</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>196.000000</td>\n      <td>8.400003e+07</td>\n      <td>3.151300e+04</td>\n      <td>8.497000e+03</td>\n      <td>742.000000</td>\n      <td>1002.899136</td>\n      <td>16100.979569</td>\n      <td>11.282093</td>\n      <td>2020.0</td>\n      <td>8.000000</td>\n      <td>3.000000</td>\n      <td>16.000000</td>\n      <td>39.059800</td>\n      <td>-86.902300</td>\n      <td>3.565287e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>260.000000</td>\n      <td>8.400004e+07</td>\n      <td>1.121210e+05</td>\n      <td>4.224950e+04</td>\n      <td>3010.750000</td>\n      <td>2122.452916</td>\n      <td>30515.969012</td>\n      <td>15.268243</td>\n      <td>2020.0</td>\n      <td>10.000000</td>\n      <td>5.000000</td>\n      <td>23.000000</td>\n      <td>42.230200</td>\n      <td>-76.802100</td>\n      <td>7.278717e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>324.000000</td>\n      <td>8.400006e+07</td>\n      <td>1.482551e+06</td>\n      <td>1.074579e+06</td>\n      <td>35266.000000</td>\n      <td>11710.000000</td>\n      <td>159983.423970</td>\n      <td>38.501190</td>\n      <td>2020.0</td>\n      <td>12.000000</td>\n      <td>6.000000</td>\n      <td>31.000000</td>\n      <td>61.370700</td>\n      <td>145.673900</td>\n      <td>3.294663e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "us_df = us_df.loc[pd.notnull(us_df.population)]\n",
    "us_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(51, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        State State Code Region            Division\n",
       "0      Alaska         AK   West             Pacific\n",
       "1     Alabama         AL  South  East South Central\n",
       "2    Arkansas         AR  South  West South Central\n",
       "3     Arizona         AZ   West            Mountain\n",
       "4  California         CA   West             Pacific"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>State Code</th>\n      <th>Region</th>\n      <th>Division</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alaska</td>\n      <td>AK</td>\n      <td>West</td>\n      <td>Pacific</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>South</td>\n      <td>West South Central</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>West</td>\n      <td>Mountain</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>CA</td>\n      <td>West</td>\n      <td>Pacific</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "states_df = pd.read_csv('https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv')\n",
    "print(states_df.shape)\n",
    "states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(51, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        state state code region            division\n",
       "0      Alaska         AK   West             Pacific\n",
       "1     Alabama         AL  South  East South Central\n",
       "2    Arkansas         AR  South  West South Central\n",
       "3     Arizona         AZ   West            Mountain\n",
       "4  California         CA   West             Pacific"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>state code</th>\n      <th>region</th>\n      <th>division</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alaska</td>\n      <td>AK</td>\n      <td>West</td>\n      <td>Pacific</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>South</td>\n      <td>West South Central</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>West</td>\n      <td>Mountain</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>CA</td>\n      <td>West</td>\n      <td>Pacific</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "states_df = states_df.rename(columns=lambda col: col.lower())\n",
    "print(states_df.shape)\n",
    "states_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['West', 'South', 'Northeast', 'Midwest'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "states_df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14347, 19)\n(14347, 22)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     date_id  location_id  cases  recoveries  deaths  cases_100k  \\\n",
       "21        52     84000001      5         0.0     0.0         5.0   \n",
       "155       53     84000001      6         0.0     0.0         6.0   \n",
       "152       54     84000001     12         0.0     0.0        12.0   \n",
       "221       55     84000001     29         0.0     0.0        29.0   \n",
       "154       56     84000001     39         0.0     0.0        39.0   \n",
       "\n",
       "     testing_rate  hospitalization_rate        date  year  ...  day_of_month  \\\n",
       "21            NaN                   NaN  2020-03-13  2020  ...            13   \n",
       "155           NaN                   NaN  2020-03-14  2020  ...            14   \n",
       "152           NaN                   NaN  2020-03-15  2020  ...            15   \n",
       "221           NaN                   NaN  2020-03-16  2020  ...            16   \n",
       "154           NaN                   NaN  2020-03-17  2020  ...            17   \n",
       "\n",
       "     country    state  city latitude longitude  population  state code  \\\n",
       "21        US  Alabama  None  32.3182  -86.9023   4903185.0          AL   \n",
       "155       US  Alabama  None  32.3182  -86.9023   4903185.0          AL   \n",
       "152       US  Alabama  None  32.3182  -86.9023   4903185.0          AL   \n",
       "221       US  Alabama  None  32.3182  -86.9023   4903185.0          AL   \n",
       "154       US  Alabama  None  32.3182  -86.9023   4903185.0          AL   \n",
       "\n",
       "     region            division  \n",
       "21    South  East South Central  \n",
       "155   South  East South Central  \n",
       "152   South  East South Central  \n",
       "221   South  East South Central  \n",
       "154   South  East South Central  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>location_id</th>\n      <th>cases</th>\n      <th>recoveries</th>\n      <th>deaths</th>\n      <th>cases_100k</th>\n      <th>testing_rate</th>\n      <th>hospitalization_rate</th>\n      <th>date</th>\n      <th>year</th>\n      <th>...</th>\n      <th>day_of_month</th>\n      <th>country</th>\n      <th>state</th>\n      <th>city</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>population</th>\n      <th>state code</th>\n      <th>region</th>\n      <th>division</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>52</td>\n      <td>84000001</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-13</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>13</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>53</td>\n      <td>84000001</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-14</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>14</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>54</td>\n      <td>84000001</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-15</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>15</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>55</td>\n      <td>84000001</td>\n      <td>29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-16</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>16</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>56</td>\n      <td>84000001</td>\n      <td>39</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-17</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>17</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(us_df.shape)\n",
    "us2_df = us_df.join(states_df.set_index('state'), on='state').sort_values(['state', 'date'])\n",
    "print(us2_df.shape)\n",
    "us2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14347, 23)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     date_id  location_id  cases  recoveries  deaths  cases_100k  \\\n",
       "21        52     84000001      5         0.0     0.0         5.0   \n",
       "155       53     84000001      6         0.0     0.0         6.0   \n",
       "152       54     84000001     12         0.0     0.0        12.0   \n",
       "221       55     84000001     29         0.0     0.0        29.0   \n",
       "154       56     84000001     39         0.0     0.0        39.0   \n",
       "\n",
       "     testing_rate  hospitalization_rate        date  year  ...  country  \\\n",
       "21            NaN                   NaN  2020-03-13  2020  ...       US   \n",
       "155           NaN                   NaN  2020-03-14  2020  ...       US   \n",
       "152           NaN                   NaN  2020-03-15  2020  ...       US   \n",
       "221           NaN                   NaN  2020-03-16  2020  ...       US   \n",
       "154           NaN                   NaN  2020-03-17  2020  ...       US   \n",
       "\n",
       "       state  city latitude longitude population  state code  region  \\\n",
       "21   Alabama  None  32.3182  -86.9023  4903185.0          AL   South   \n",
       "155  Alabama  None  32.3182  -86.9023  4903185.0          AL   South   \n",
       "152  Alabama  None  32.3182  -86.9023  4903185.0          AL   South   \n",
       "221  Alabama  None  32.3182  -86.9023  4903185.0          AL   South   \n",
       "154  Alabama  None  32.3182  -86.9023  4903185.0          AL   South   \n",
       "\n",
       "               division cases_norm100k  \n",
       "21   East South Central       0.101975  \n",
       "155  East South Central       0.122369  \n",
       "152  East South Central       0.244739  \n",
       "221  East South Central       0.591452  \n",
       "154  East South Central       0.795401  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>location_id</th>\n      <th>cases</th>\n      <th>recoveries</th>\n      <th>deaths</th>\n      <th>cases_100k</th>\n      <th>testing_rate</th>\n      <th>hospitalization_rate</th>\n      <th>date</th>\n      <th>year</th>\n      <th>...</th>\n      <th>country</th>\n      <th>state</th>\n      <th>city</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>population</th>\n      <th>state code</th>\n      <th>region</th>\n      <th>division</th>\n      <th>cases_norm100k</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>52</td>\n      <td>84000001</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-13</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>0.101975</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>53</td>\n      <td>84000001</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-14</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>0.122369</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>54</td>\n      <td>84000001</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-15</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>0.244739</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>55</td>\n      <td>84000001</td>\n      <td>29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-16</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>0.591452</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>56</td>\n      <td>84000001</td>\n      <td>39</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-03-17</td>\n      <td>2020</td>\n      <td>...</td>\n      <td>US</td>\n      <td>Alabama</td>\n      <td>None</td>\n      <td>32.3182</td>\n      <td>-86.9023</td>\n      <td>4903185.0</td>\n      <td>AL</td>\n      <td>South</td>\n      <td>East South Central</td>\n      <td>0.795401</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "us2_df['cases_norm100k'] = us2_df.cases / (us2_df.population / 100_000)\n",
    "print(us2_df.shape)\n",
    "us2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14347, 24)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        date_id  location_id  cases  recoveries  deaths   cases_100k  \\\n",
       "21          52     84000001      5         0.0     0.0     5.000000   \n",
       "155         53     84000001      6         0.0     0.0     6.000000   \n",
       "152         54     84000001     12         0.0     0.0    12.000000   \n",
       "221         55     84000001     29         0.0     0.0    29.000000   \n",
       "154         56     84000001     39         0.0     0.0    39.000000   \n",
       "...        ...          ...    ...         ...     ...          ...   \n",
       "14998      324     84000056  38223     33891.0   299.0  6604.303346   \n",
       "15158       57          840      1       106.0     0.0     1.000000   \n",
       "15159       58          840      1       108.0     0.0     1.000000   \n",
       "15160       59          840      1       147.0     0.0     1.000000   \n",
       "15157       60          840      1       171.0     0.0     1.000000   \n",
       "\n",
       "       testing_rate  hospitalization_rate        date  year  ...    state  \\\n",
       "21              NaN                   NaN  2020-03-13  2020  ...  Alabama   \n",
       "155             NaN                   NaN  2020-03-14  2020  ...  Alabama   \n",
       "152             NaN                   NaN  2020-03-15  2020  ...  Alabama   \n",
       "221             NaN                   NaN  2020-03-16  2020  ...  Alabama   \n",
       "154             NaN                   NaN  2020-03-17  2020  ...  Alabama   \n",
       "...             ...                   ...         ...   ...  ...      ...   \n",
       "14998  75516.752223                   NaN  2020-12-10  2020  ...  Wyoming   \n",
       "15158           NaN                   NaN  2020-03-18  2020  ...     None   \n",
       "15159           NaN                   NaN  2020-03-19  2020  ...     None   \n",
       "15160           NaN                   NaN  2020-03-20  2020  ...     None   \n",
       "15157           NaN                   NaN  2020-03-21  2020  ...     None   \n",
       "\n",
       "       city  latitude longitude   population state code  region  \\\n",
       "21     None   32.3182  -86.9023    4903185.0         AL   South   \n",
       "155    None   32.3182  -86.9023    4903185.0         AL   South   \n",
       "152    None   32.3182  -86.9023    4903185.0         AL   South   \n",
       "221    None   32.3182  -86.9023    4903185.0         AL   South   \n",
       "154    None   32.3182  -86.9023    4903185.0         AL   South   \n",
       "...     ...       ...       ...          ...        ...     ...   \n",
       "14998  None   42.7560 -107.3025     578759.0         WY    West   \n",
       "15158  None   40.0000 -100.0000  329466283.0        NaN     NaN   \n",
       "15159  None   40.0000 -100.0000  329466283.0        NaN     NaN   \n",
       "15160  None   40.0000 -100.0000  329466283.0        NaN     NaN   \n",
       "15157  None   40.0000 -100.0000  329466283.0        NaN     NaN   \n",
       "\n",
       "                 division  cases_norm100k recoveries_norm100k  \n",
       "21     East South Central        0.101975            0.000000  \n",
       "155    East South Central        0.122369            0.000000  \n",
       "152    East South Central        0.244739            0.000000  \n",
       "221    East South Central        0.591452            0.000000  \n",
       "154    East South Central        0.795401            0.000000  \n",
       "...                   ...             ...                 ...  \n",
       "14998            Mountain     6604.303346         5855.805266  \n",
       "15158                 NaN        0.000304            0.032173  \n",
       "15159                 NaN        0.000304            0.032780  \n",
       "15160                 NaN        0.000304            0.044618  \n",
       "15157                 NaN        0.000304            0.051902  \n",
       "\n",
       "[14347 rows x 24 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "us2_df['recoveries_norm100k'] = us2_df.recoveries / (us2_df.population / 100_000)\n",
    "print(us2_df.shape)\n",
    "us2_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14347, 25)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        date_id  location_id  cases  recoveries  deaths   cases_100k  \\\n",
       "21          52     84000001      5         0.0     0.0     5.000000   \n",
       "155         53     84000001      6         0.0     0.0     6.000000   \n",
       "152         54     84000001     12         0.0     0.0    12.000000   \n",
       "221         55     84000001     29         0.0     0.0    29.000000   \n",
       "154         56     84000001     39         0.0     0.0    39.000000   \n",
       "...        ...          ...    ...         ...     ...          ...   \n",
       "14998      324     84000056  38223     33891.0   299.0  6604.303346   \n",
       "15158       57          840      1       106.0     0.0     1.000000   \n",
       "15159       58          840      1       108.0     0.0     1.000000   \n",
       "15160       59          840      1       147.0     0.0     1.000000   \n",
       "15157       60          840      1       171.0     0.0     1.000000   \n",
       "\n",
       "       testing_rate  hospitalization_rate        date  year  ...  city  \\\n",
       "21              NaN                   NaN  2020-03-13  2020  ...  None   \n",
       "155             NaN                   NaN  2020-03-14  2020  ...  None   \n",
       "152             NaN                   NaN  2020-03-15  2020  ...  None   \n",
       "221             NaN                   NaN  2020-03-16  2020  ...  None   \n",
       "154             NaN                   NaN  2020-03-17  2020  ...  None   \n",
       "...             ...                   ...         ...   ...  ...   ...   \n",
       "14998  75516.752223                   NaN  2020-12-10  2020  ...  None   \n",
       "15158           NaN                   NaN  2020-03-18  2020  ...  None   \n",
       "15159           NaN                   NaN  2020-03-19  2020  ...  None   \n",
       "15160           NaN                   NaN  2020-03-20  2020  ...  None   \n",
       "15157           NaN                   NaN  2020-03-21  2020  ...  None   \n",
       "\n",
       "       latitude  longitude   population state code region            division  \\\n",
       "21      32.3182   -86.9023    4903185.0         AL  South  East South Central   \n",
       "155     32.3182   -86.9023    4903185.0         AL  South  East South Central   \n",
       "152     32.3182   -86.9023    4903185.0         AL  South  East South Central   \n",
       "221     32.3182   -86.9023    4903185.0         AL  South  East South Central   \n",
       "154     32.3182   -86.9023    4903185.0         AL  South  East South Central   \n",
       "...         ...        ...          ...        ...    ...                 ...   \n",
       "14998   42.7560  -107.3025     578759.0         WY   West            Mountain   \n",
       "15158   40.0000  -100.0000  329466283.0        NaN    NaN                 NaN   \n",
       "15159   40.0000  -100.0000  329466283.0        NaN    NaN                 NaN   \n",
       "15160   40.0000  -100.0000  329466283.0        NaN    NaN                 NaN   \n",
       "15157   40.0000  -100.0000  329466283.0        NaN    NaN                 NaN   \n",
       "\n",
       "       cases_norm100k  recoveries_norm100k deaths_norm100k  \n",
       "21           0.101975             0.000000        0.000000  \n",
       "155          0.122369             0.000000        0.000000  \n",
       "152          0.244739             0.000000        0.000000  \n",
       "221          0.591452             0.000000        0.000000  \n",
       "154          0.795401             0.000000        0.000000  \n",
       "...               ...                  ...             ...  \n",
       "14998     6604.303346          5855.805266       51.662264  \n",
       "15158        0.000304             0.032173        0.000000  \n",
       "15159        0.000304             0.032780        0.000000  \n",
       "15160        0.000304             0.044618        0.000000  \n",
       "15157        0.000304             0.051902        0.000000  \n",
       "\n",
       "[14347 rows x 25 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "us2_df['deaths_norm100k'] = us2_df.deaths / (us2_df.population / 100_000)\n",
    "print(us2_df.shape)\n",
    "us2_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14347, 25)\n(14347, 28)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['date_id', 'cases', 'recoveries', 'deaths', 'cases_100k',\n",
       "       'testing_rate', 'hospitalization_rate', 'date', 'country', 'state',\n",
       "       'population', 'cases_norm100k', 'recoveries_norm100k',\n",
       "       'deaths_norm100k', 'region_Midwest', 'region_Northeast', 'region_South',\n",
       "       'region_West'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "us3_df = pd.get_dummies(us2_df, columns = ['region'])\n",
    "print(us2_df.shape)\n",
    "print(us3_df.shape)\n",
    "us3_df = us3_df.drop(['year','month','state code', 'day_of_week', 'longitude', 'division', 'location_id', 'day_of_month', 'city', 'latitude'], axis = 1)\n",
    "us3_df.columns\n"
   ]
  },
  {
   "source": [
    "# Segment Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_df(df, group_fields):\n",
    "    grouped = df.groupby(group_fields)\n",
    "    flattened_df = pd.DataFrame()\n",
    "    for name, group in grouped:\n",
    "        row = {}\n",
    "        row['cases'] = group.cases.sum()\n",
    "        #row['recoveries'] = group.recoveries.sum()\n",
    "        #row['deaths'] = group.deaths.sum()\n",
    "        #row['cases_100k'] = group.cases_100k.sum()\n",
    "        row['testing_rate'] = group.testing_rate.mean()\n",
    "        #row['hospitalization_rate'] = group.hospitalization_rate.mean()\n",
    "        #row['date'] = group.date.values[0]\n",
    "        #row['population'] = group.population.sum()\n",
    "        row['cases_norm100k'] = group.cases_norm100k.sum()\n",
    "        row['recoveries_norm100k'] = group.recoveries_norm100k.sum()\n",
    "        row['deaths_norm100k'] = group.deaths_norm100k.sum()\n",
    "        for state in group.state.values:\n",
    "            state_data =  group[group.state == state]\n",
    "            row[state+'_cases_norm100k'] = state_data.cases_norm100k.values[0]\n",
    "            row[state+'_recoveries_norm100k'] = state_data.recoveries_norm100k.values[0]\n",
    "            row[state+'_deaths_norm100k'] = state_data.deaths_norm100k.values[0]\n",
    "            row[state+'_testing_rate'] = state_data.testing_rate.values[0]\n",
    "            #row[state+'_hospitalization_rate'] = state_data.cases_norm100k.values[0]\n",
    "        flattened_df = flattened_df.append(row, ignore_index = True)\n",
    "    return flattened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, segment_time_frame, days_out):\n",
    "    X = pd.DataFrame()\n",
    "    y = []\n",
    "    data_df = pd.DataFrame()\n",
    "    loop_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        loop_count = loop_count + 1\n",
    "        data_df = data_df.append(row)\n",
    "        if data_df.shape[0] >= segment_time_frame:\n",
    "            #Calculate Features\n",
    "            features = {}\n",
    "            for column in data_df.columns:\n",
    "                if column != 'cases':\n",
    "                    features['Max_' + column] = data_df[column].max()\n",
    "                    features['Min_' + column] = data_df[column].min()\n",
    "                    features['AVG_' + column] = data_df[column].mean()\n",
    "                    if segment_time_frame > 1:\n",
    "                        features[column + '_2'] = data_df[column].values[-1] - data_df[column].values[-2]\n",
    "                        if segment_time_frame >= 3:\n",
    "                            features[column + '_3'] = data_df[column].values[-1] - data_df[column].values[-3]\n",
    "                            if segment_time_frame >= 5:\n",
    "                                features[column + '_5'] = data_df[column].values[-1] - data_df[column].values[-5]\n",
    "                                if segment_time_frame >= 7:\n",
    "                                    features[column + '_7'] = data_df[column].values[-1] - data_df[column].values[-7]\n",
    "                                    if segment_time_frame >= 8:\n",
    "                                        features[column + '_' + str(segment_time_frame)] = data_df[column].values[-1] - data_df[column].values[-segment_time_frame]\n",
    "            #Append Features\n",
    "            X = X.append(features, ignore_index = True)\n",
    "            data_df = data_df.iloc[1:,:]\n",
    "            try:\n",
    "                y.append(df.cases[index + days_out])\n",
    "            except:\n",
    "                y.append(-1)\n",
    "                break\n",
    "    return X.iloc[:-1, :], y[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_northeast_df = us3_df[us3_df.region_Northeast == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_south_df = us3_df[us3_df.region_South== 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_midwest_df = us3_df[us3_df.region_Midwest == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)\n",
    "us_west_df = us3_df[us3_df.region_West == 1].drop(['region_Midwest', 'region_Northeast',  'region_South', 'region_West'], axis = 1)"
   ]
  },
  {
   "source": [
    "# Northeast Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Connecticut_cases_norm100k', 'Connecticut_deaths_norm100k',\n       'Connecticut_recoveries_norm100k', 'Connecticut_testing_rate',\n       'Maine_cases_norm100k', 'Maine_deaths_norm100k',\n       'Maine_recoveries_norm100k', 'Maine_testing_rate',\n       'Massachusetts_cases_norm100k', 'Massachusetts_deaths_norm100k',\n       'Massachusetts_recoveries_norm100k', 'Massachusetts_testing_rate',\n       'New Hampshire_cases_norm100k', 'New Hampshire_deaths_norm100k',\n       'New Hampshire_recoveries_norm100k', 'New Hampshire_testing_rate',\n       'New Jersey_cases_norm100k', 'New Jersey_deaths_norm100k',\n       'New Jersey_recoveries_norm100k', 'New Jersey_testing_rate',\n       'New York_cases_norm100k', 'New York_deaths_norm100k',\n       'New York_recoveries_norm100k', 'New York_testing_rate',\n       'Pennsylvania_cases_norm100k', 'Pennsylvania_deaths_norm100k',\n       'Pennsylvania_recoveries_norm100k', 'Pennsylvania_testing_rate',\n       'Rhode Island_cases_norm100k', 'Rhode Island_deaths_norm100k',\n       'Rhode Island_recoveries_norm100k', 'Rhode Island_testing_rate',\n       'Vermont_cases_norm100k', 'Vermont_deaths_norm100k',\n       'Vermont_recoveries_norm100k', 'Vermont_testing_rate', 'cases',\n       'cases_norm100k', 'deaths_norm100k', 'recoveries_norm100k',\n       'testing_rate'],\n      dtype='object')\n(255, 41)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Connecticut_cases_norm100k  Connecticut_deaths_norm100k  \\\n",
       "0                    0.056096                          0.0   \n",
       "1                    0.084145                          0.0   \n",
       "2                    0.140241                          0.0   \n",
       "3                    0.308531                          0.0   \n",
       "4                    0.617061                          0.0   \n",
       "\n",
       "   Connecticut_recoveries_norm100k  Connecticut_testing_rate  \\\n",
       "0                              0.0                       NaN   \n",
       "1                              0.0                       NaN   \n",
       "2                              0.0                       NaN   \n",
       "3                              0.0                       NaN   \n",
       "4                              0.0                       NaN   \n",
       "\n",
       "   Maine_cases_norm100k  Maine_deaths_norm100k  Maine_recoveries_norm100k  \\\n",
       "0              0.000000                    0.0                        0.0   \n",
       "1              0.000000                    0.0                        0.0   \n",
       "2              0.000000                    0.0                        0.0   \n",
       "3              0.074393                    0.0                        0.0   \n",
       "4              0.223179                    0.0                        0.0   \n",
       "\n",
       "   Maine_testing_rate  Massachusetts_cases_norm100k  \\\n",
       "0                 NaN                      1.334784   \n",
       "1                 NaN                      1.378309   \n",
       "2                 NaN                      1.566920   \n",
       "3                 NaN                      1.784548   \n",
       "4                 NaN                      2.002175   \n",
       "\n",
       "   Massachusetts_deaths_norm100k  ...  Rhode Island_testing_rate  \\\n",
       "0                            0.0  ...                        NaN   \n",
       "1                            0.0  ...                        NaN   \n",
       "2                            0.0  ...                        NaN   \n",
       "3                            0.0  ...                        NaN   \n",
       "4                            0.0  ...                        NaN   \n",
       "\n",
       "   Vermont_cases_norm100k  Vermont_deaths_norm100k  \\\n",
       "0                0.160259                      0.0   \n",
       "1                0.160259                      0.0   \n",
       "2                0.320518                      0.0   \n",
       "3                0.320518                      0.0   \n",
       "4                0.801296                      0.0   \n",
       "\n",
       "   Vermont_recoveries_norm100k  Vermont_testing_rate  cases  cases_norm100k  \\\n",
       "0                          0.0                   NaN  302.0        3.280419   \n",
       "1                          0.0                   NaN  368.0        3.977245   \n",
       "2                          0.0                   NaN  505.0        5.125343   \n",
       "3                          0.0                   NaN  648.0        7.061698   \n",
       "4                          0.0                   NaN  836.0        9.889158   \n",
       "\n",
       "   deaths_norm100k  recoveries_norm100k  testing_rate  \n",
       "0         0.011258             0.014509           NaN  \n",
       "1         0.011258             0.014509           NaN  \n",
       "2         0.011258             0.014509           NaN  \n",
       "3         0.011258             0.014509           NaN  \n",
       "4         0.021539             0.014509           NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Connecticut_cases_norm100k</th>\n      <th>Connecticut_deaths_norm100k</th>\n      <th>Connecticut_recoveries_norm100k</th>\n      <th>Connecticut_testing_rate</th>\n      <th>Maine_cases_norm100k</th>\n      <th>Maine_deaths_norm100k</th>\n      <th>Maine_recoveries_norm100k</th>\n      <th>Maine_testing_rate</th>\n      <th>Massachusetts_cases_norm100k</th>\n      <th>Massachusetts_deaths_norm100k</th>\n      <th>...</th>\n      <th>Rhode Island_testing_rate</th>\n      <th>Vermont_cases_norm100k</th>\n      <th>Vermont_deaths_norm100k</th>\n      <th>Vermont_recoveries_norm100k</th>\n      <th>Vermont_testing_rate</th>\n      <th>cases</th>\n      <th>cases_norm100k</th>\n      <th>deaths_norm100k</th>\n      <th>recoveries_norm100k</th>\n      <th>testing_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.056096</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.334784</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.160259</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>302.0</td>\n      <td>3.280419</td>\n      <td>0.011258</td>\n      <td>0.014509</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.084145</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.378309</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.160259</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>368.0</td>\n      <td>3.977245</td>\n      <td>0.011258</td>\n      <td>0.014509</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.140241</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.566920</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.320518</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>505.0</td>\n      <td>5.125343</td>\n      <td>0.011258</td>\n      <td>0.014509</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.308531</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.074393</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.784548</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.320518</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>648.0</td>\n      <td>7.061698</td>\n      <td>0.011258</td>\n      <td>0.014509</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.617061</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.223179</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.002175</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.801296</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>836.0</td>\n      <td>9.889158</td>\n      <td>0.021539</td>\n      <td>0.014509</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "northeast_flattened_df = flatten_df(us_northeast_df, ['date'])\n",
    "print(northeast_flattened_df.columns)\n",
    "print(northeast_flattened_df.shape)\n",
    "northeast_flattened_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "234\n(234, 320)\n[456252.0, 469860.0, 480675.0, 499110.0, 517459.0]\n(234, 320)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AVG_Connecticut_cases_norm100k  AVG_Connecticut_deaths_norm100k  \\\n",
       "0                       75.141216                         3.433104   \n",
       "1                      102.727588                         5.056161   \n",
       "2                      132.423187                         6.871817   \n",
       "3                      163.844687                         8.809015   \n",
       "4                      196.640551                        10.839707   \n",
       "\n",
       "   AVG_Connecticut_recoveries_norm100k  AVG_Connecticut_testing_rate  \\\n",
       "0                                  0.0                   1228.232117   \n",
       "1                                  0.0                   1272.779723   \n",
       "2                                  0.0                   1316.219424   \n",
       "3                                  0.0                   1356.118035   \n",
       "4                                  0.0                   1384.617043   \n",
       "\n",
       "   AVG_Maine_cases_norm100k  AVG_Maine_deaths_norm100k  \\\n",
       "0                 11.659867                   0.287653   \n",
       "1                 15.478709                   0.406682   \n",
       "2                 19.426499                   0.540589   \n",
       "3                 23.528035                   0.684416   \n",
       "4                 27.723802                   0.843121   \n",
       "\n",
       "   AVG_Maine_recoveries_norm100k  AVG_Maine_testing_rate  \\\n",
       "0                       4.121374              890.654165   \n",
       "1                       5.634032              984.130405   \n",
       "2                       7.285557             1040.659077   \n",
       "3                       9.031314             1078.784947   \n",
       "4                      10.925856             1106.261078   \n",
       "\n",
       "   AVG_Massachusetts_cases_norm100k  AVG_Massachusetts_deaths_norm100k  ...  \\\n",
       "0                         80.401367                           2.365856  ...   \n",
       "1                        109.250104                           3.437551  ...   \n",
       "2                        140.284790                           4.509247  ...   \n",
       "3                        173.455129                           5.713454  ...   \n",
       "4                        208.516413                           7.071451  ...   \n",
       "\n",
       "   recoveries_norm100k_15  recoveries_norm100k_2  recoveries_norm100k_3  \\\n",
       "0              177.958249               2.148918              12.329957   \n",
       "1              190.571668              12.613419              14.762337   \n",
       "2              193.976224               3.404556              16.017976   \n",
       "3              203.330297               9.354073              12.758629   \n",
       "4              208.500500               5.170203              14.524276   \n",
       "\n",
       "   recoveries_norm100k_5  recoveries_norm100k_7  testing_rate_15  \\\n",
       "0             177.972757             177.972757      5070.487311   \n",
       "1             190.586177             190.586177      5070.487311   \n",
       "2              28.347933             193.990733      5070.487311   \n",
       "3              27.520966             203.344805      5070.487311   \n",
       "4              30.542252              42.872209      5070.487311   \n",
       "\n",
       "   testing_rate_2  testing_rate_3  testing_rate_5  testing_rate_7  \n",
       "0       73.220709      178.279575     1460.450058     2184.188190  \n",
       "1      117.583316      190.804025     1460.450058     2184.188190  \n",
       "2       83.563255      201.146571      379.426146     2184.188190  \n",
       "3       76.633068      160.196323      351.000349     2184.188190  \n",
       "4       86.756894      163.389963      364.536534      542.816109  \n",
       "\n",
       "[5 rows x 320 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AVG_Connecticut_cases_norm100k</th>\n      <th>AVG_Connecticut_deaths_norm100k</th>\n      <th>AVG_Connecticut_recoveries_norm100k</th>\n      <th>AVG_Connecticut_testing_rate</th>\n      <th>AVG_Maine_cases_norm100k</th>\n      <th>AVG_Maine_deaths_norm100k</th>\n      <th>AVG_Maine_recoveries_norm100k</th>\n      <th>AVG_Maine_testing_rate</th>\n      <th>AVG_Massachusetts_cases_norm100k</th>\n      <th>AVG_Massachusetts_deaths_norm100k</th>\n      <th>...</th>\n      <th>recoveries_norm100k_15</th>\n      <th>recoveries_norm100k_2</th>\n      <th>recoveries_norm100k_3</th>\n      <th>recoveries_norm100k_5</th>\n      <th>recoveries_norm100k_7</th>\n      <th>testing_rate_15</th>\n      <th>testing_rate_2</th>\n      <th>testing_rate_3</th>\n      <th>testing_rate_5</th>\n      <th>testing_rate_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75.141216</td>\n      <td>3.433104</td>\n      <td>0.0</td>\n      <td>1228.232117</td>\n      <td>11.659867</td>\n      <td>0.287653</td>\n      <td>4.121374</td>\n      <td>890.654165</td>\n      <td>80.401367</td>\n      <td>2.365856</td>\n      <td>...</td>\n      <td>177.958249</td>\n      <td>2.148918</td>\n      <td>12.329957</td>\n      <td>177.972757</td>\n      <td>177.972757</td>\n      <td>5070.487311</td>\n      <td>73.220709</td>\n      <td>178.279575</td>\n      <td>1460.450058</td>\n      <td>2184.188190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102.727588</td>\n      <td>5.056161</td>\n      <td>0.0</td>\n      <td>1272.779723</td>\n      <td>15.478709</td>\n      <td>0.406682</td>\n      <td>5.634032</td>\n      <td>984.130405</td>\n      <td>109.250104</td>\n      <td>3.437551</td>\n      <td>...</td>\n      <td>190.571668</td>\n      <td>12.613419</td>\n      <td>14.762337</td>\n      <td>190.586177</td>\n      <td>190.586177</td>\n      <td>5070.487311</td>\n      <td>117.583316</td>\n      <td>190.804025</td>\n      <td>1460.450058</td>\n      <td>2184.188190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>132.423187</td>\n      <td>6.871817</td>\n      <td>0.0</td>\n      <td>1316.219424</td>\n      <td>19.426499</td>\n      <td>0.540589</td>\n      <td>7.285557</td>\n      <td>1040.659077</td>\n      <td>140.284790</td>\n      <td>4.509247</td>\n      <td>...</td>\n      <td>193.976224</td>\n      <td>3.404556</td>\n      <td>16.017976</td>\n      <td>28.347933</td>\n      <td>193.990733</td>\n      <td>5070.487311</td>\n      <td>83.563255</td>\n      <td>201.146571</td>\n      <td>379.426146</td>\n      <td>2184.188190</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>163.844687</td>\n      <td>8.809015</td>\n      <td>0.0</td>\n      <td>1356.118035</td>\n      <td>23.528035</td>\n      <td>0.684416</td>\n      <td>9.031314</td>\n      <td>1078.784947</td>\n      <td>173.455129</td>\n      <td>5.713454</td>\n      <td>...</td>\n      <td>203.330297</td>\n      <td>9.354073</td>\n      <td>12.758629</td>\n      <td>27.520966</td>\n      <td>203.344805</td>\n      <td>5070.487311</td>\n      <td>76.633068</td>\n      <td>160.196323</td>\n      <td>351.000349</td>\n      <td>2184.188190</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>196.640551</td>\n      <td>10.839707</td>\n      <td>0.0</td>\n      <td>1384.617043</td>\n      <td>27.723802</td>\n      <td>0.843121</td>\n      <td>10.925856</td>\n      <td>1106.261078</td>\n      <td>208.516413</td>\n      <td>7.071451</td>\n      <td>...</td>\n      <td>208.500500</td>\n      <td>5.170203</td>\n      <td>14.524276</td>\n      <td>30.542252</td>\n      <td>42.872209</td>\n      <td>5070.487311</td>\n      <td>86.756894</td>\n      <td>163.389963</td>\n      <td>364.536534</td>\n      <td>542.816109</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 320 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "northeast_X, northeast_y = sliding_window(northeast_flattened_df, 15, 7)\n",
    "print(len(northeast_y))\n",
    "print(northeast_X.shape)\n",
    "print(northeast_y[:5])\n",
    "northeast_X = northeast_X.fillna(northeast_X.mean())\n",
    "print(northeast_X.shape)\n",
    "northeast_X.head()"
   ]
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "northeast_X_train, northeast_X_test, northeast_y_train, northeast_y_test = train_test_split(northeast_X, northeast_y, test_size = .25)\n",
    "northeast_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(northeast_X_train), columns = northeast_X_train.columns) + 1\n",
    "northeast_transformed_X_test = pd.DataFrame(Normalizer().transform(northeast_X_test), columns = northeast_X_test.columns) + 1\n",
    "\n",
    "selected_col_idx = SelectKBest(chi2, k = 15).fit(northeast_transformed_X_train, northeast_y_train).get_support(indices = True)\n",
    "northeast_selected_X_train = northeast_transformed_X_train.iloc[:, selected_col_idx]\n",
    "northeast_selected_X_test = northeast_transformed_X_test.iloc[:, selected_col_idx]\n",
    "\n",
    "northeast_selected_X_train = northeast_selected_X_train.drop(['New York_testing_rate_15', 'Rhode Island_testing_rate_15', 'Max_cases_norm100k', 'AVG_cases_norm100k', 'Max_Massachusetts_testing_rate'], axis = 1)\n",
    "northeast_selected_X_test = northeast_selected_X_test.drop(['New York_testing_rate_15', 'Rhode Island_testing_rate_15', 'Max_cases_norm100k', 'AVG_cases_norm100k', 'Max_Massachusetts_testing_rate'], axis = 1)\n",
    "corr_matrix = northeast_selected_X_train.corr('spearman')\n",
    "for row_idx, row in corr_matrix.iterrows():\n",
    "    for col_idx, cor in row.iteritems():\n",
    "        if col_idx != row_idx and cor > .8:\n",
    "            print(str(row_idx) + ' ' + str(col_idx) + ' = ' + str(corr_matrix.loc[row_idx, col_idx]))\n",
    "print(northeast_selected_X_test.columns)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLUMNS = ['AVG_Massachusetts_testing_rate', 'AVG_Rhode Island_testing_rate', 'Connecticut_testing_rate_15', 'Massachusetts_testing_rate_15', 'Max_Rhode Island_testing_rate', 'Min_Rhode Island_testing_rate', 'Min_cases_norm100k', 'Vermont_testing_rate_15', 'cases_norm100k_15', 'testing_rate_15']\n",
    "northeast_X_train, northeast_X_test, northeast_y_train, northeast_y_test = train_test_split(northeast_X, northeast_y, test_size = .25)\n",
    "northeast_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(northeast_X_train), columns = northeast_X_train.columns)\n",
    "northeast_transformed_X_test = pd.DataFrame(Normalizer().transform(northeast_X_test), columns = northeast_X_test.columns)\n",
    "northeast_selected_X_train = northeast_transformed_X_train[CHOSEN_COLUMNS]\n",
    "northeast_selected_X_test = northeast_transformed_X_test[CHOSEN_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'AVG_Massachusetts_testing_rate': 4107713.7155113053, 'AVG_Rhode Island_testing_rate': 107860.42071430851, 'Connecticut_testing_rate_15': 949679.0942750452, 'Massachusetts_testing_rate_15': -2758473.786415335, 'Max_Rhode Island_testing_rate': 17526.841207527264, 'Min_Rhode Island_testing_rate': 553227.6404521097, 'Min_cases_norm100k': -3124896.420579755, 'Vermont_testing_rate_15': 549188.9129537786, 'cases_norm100k_15': 3179712.8092456074, 'testing_rate_15': -2388055.5232510287}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression().fit(northeast_selected_X_train, northeast_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(northeast_selected_X_train.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.77\nThe Mean Absolute Error: 106712.21 cases\nThe Median Absolute Error: 58984.86 cases\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(northeast_selected_X_test)\n",
    "print(\"The Explained Variance: %.2f\" % reg.score(northeast_selected_X_test, northeast_y_test))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(northeast_y_test, y_pred))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(northeast_y_test, y_pred))"
   ]
  },
  {
   "source": [
    "# South Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Arkansas_cases_norm100k', 'Arkansas_deaths_norm100k',\n       'Arkansas_recoveries_norm100k', 'Arkansas_testing_rate',\n       'Delaware_cases_norm100k', 'Delaware_deaths_norm100k',\n       'Delaware_recoveries_norm100k', 'Delaware_testing_rate',\n       'District of Columbia_cases_norm100k',\n       'District of Columbia_deaths_norm100k',\n       'District of Columbia_recoveries_norm100k',\n       'District of Columbia_testing_rate', 'Florida_cases_norm100k',\n       'Florida_deaths_norm100k', 'Florida_recoveries_norm100k',\n       'Florida_testing_rate', 'Georgia_cases_norm100k',\n       'Georgia_deaths_norm100k', 'Georgia_recoveries_norm100k',\n       'Georgia_testing_rate', 'Kentucky_cases_norm100k',\n       'Kentucky_deaths_norm100k', 'Kentucky_recoveries_norm100k',\n       'Kentucky_testing_rate', 'Louisiana_cases_norm100k',\n       'Louisiana_deaths_norm100k', 'Louisiana_recoveries_norm100k',\n       'Louisiana_testing_rate', 'Maryland_cases_norm100k',\n       'Maryland_deaths_norm100k', 'Maryland_recoveries_norm100k',\n       'Maryland_testing_rate', 'Mississippi_cases_norm100k',\n       'Mississippi_deaths_norm100k', 'Mississippi_recoveries_norm100k',\n       'Mississippi_testing_rate', 'North Carolina_cases_norm100k',\n       'North Carolina_deaths_norm100k', 'North Carolina_recoveries_norm100k',\n       'North Carolina_testing_rate', 'Oklahoma_cases_norm100k',\n       'Oklahoma_deaths_norm100k', 'Oklahoma_recoveries_norm100k',\n       'Oklahoma_testing_rate', 'South Carolina_cases_norm100k',\n       'South Carolina_deaths_norm100k', 'South Carolina_recoveries_norm100k',\n       'South Carolina_testing_rate', 'Tennessee_cases_norm100k',\n       'Tennessee_deaths_norm100k', 'Tennessee_recoveries_norm100k',\n       'Tennessee_testing_rate', 'Texas_cases_norm100k',\n       'Texas_deaths_norm100k', 'Texas_recoveries_norm100k',\n       'Texas_testing_rate', 'Virginia_cases_norm100k',\n       'Virginia_deaths_norm100k', 'Virginia_recoveries_norm100k',\n       'Virginia_testing_rate', 'West Virginia_cases_norm100k',\n       'West Virginia_deaths_norm100k', 'West Virginia_recoveries_norm100k',\n       'West Virginia_testing_rate', 'cases', 'cases_norm100k',\n       'deaths_norm100k', 'recoveries_norm100k', 'testing_rate',\n       'Alabama_cases_norm100k', 'Alabama_deaths_norm100k',\n       'Alabama_recoveries_norm100k', 'Alabama_testing_rate'],\n      dtype='object')\n(255, 73)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Arkansas_cases_norm100k  Arkansas_deaths_norm100k  \\\n",
       "0                 0.000000                       0.0   \n",
       "1                 0.033137                       0.0   \n",
       "2                 0.198820                       0.0   \n",
       "3                 0.198820                       0.0   \n",
       "4                 0.397640                       0.0   \n",
       "\n",
       "   Arkansas_recoveries_norm100k  Arkansas_testing_rate  \\\n",
       "0                           0.0                    NaN   \n",
       "1                           0.0                    NaN   \n",
       "2                           0.0                    NaN   \n",
       "3                           0.0                    NaN   \n",
       "4                           0.0                    NaN   \n",
       "\n",
       "   Delaware_cases_norm100k  Delaware_deaths_norm100k  \\\n",
       "0                 0.000000                       0.0   \n",
       "1                 0.102694                       0.0   \n",
       "2                 0.102694                       0.0   \n",
       "3                 0.410777                       0.0   \n",
       "4                 0.616166                       0.0   \n",
       "\n",
       "   Delaware_recoveries_norm100k  Delaware_testing_rate  \\\n",
       "0                           0.0                    NaN   \n",
       "1                           0.0                    NaN   \n",
       "2                           0.0                    NaN   \n",
       "3                           0.0                    NaN   \n",
       "4                           0.0                    NaN   \n",
       "\n",
       "   District of Columbia_cases_norm100k  District of Columbia_deaths_norm100k  \\\n",
       "0                             0.708467                                   0.0   \n",
       "1                             1.416934                                   0.0   \n",
       "2                             1.416934                                   0.0   \n",
       "3                             1.416934                                   0.0   \n",
       "4                             1.416934                                   0.0   \n",
       "\n",
       "   ...  West Virginia_testing_rate  cases  cases_norm100k  deaths_norm100k  \\\n",
       "0  ...                         NaN   95.0        1.709144         0.009312   \n",
       "1  ...                         NaN  144.0        2.977917         0.009312   \n",
       "2  ...                         NaN  216.0        4.020499         0.018730   \n",
       "3  ...                         NaN  317.0        5.521583         0.018730   \n",
       "4  ...                         NaN  476.0        7.974398         0.056613   \n",
       "\n",
       "   recoveries_norm100k  testing_rate  Alabama_cases_norm100k  \\\n",
       "0                  0.0           NaN                     NaN   \n",
       "1                  0.0           NaN                     NaN   \n",
       "2                  0.0           NaN                     NaN   \n",
       "3                  0.0           NaN                0.101975   \n",
       "4                  0.0           NaN                0.122369   \n",
       "\n",
       "   Alabama_deaths_norm100k  Alabama_recoveries_norm100k  Alabama_testing_rate  \n",
       "0                      NaN                          NaN                   NaN  \n",
       "1                      NaN                          NaN                   NaN  \n",
       "2                      NaN                          NaN                   NaN  \n",
       "3                      0.0                          0.0                   NaN  \n",
       "4                      0.0                          0.0                   NaN  \n",
       "\n",
       "[5 rows x 73 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Arkansas_cases_norm100k</th>\n      <th>Arkansas_deaths_norm100k</th>\n      <th>Arkansas_recoveries_norm100k</th>\n      <th>Arkansas_testing_rate</th>\n      <th>Delaware_cases_norm100k</th>\n      <th>Delaware_deaths_norm100k</th>\n      <th>Delaware_recoveries_norm100k</th>\n      <th>Delaware_testing_rate</th>\n      <th>District of Columbia_cases_norm100k</th>\n      <th>District of Columbia_deaths_norm100k</th>\n      <th>...</th>\n      <th>West Virginia_testing_rate</th>\n      <th>cases</th>\n      <th>cases_norm100k</th>\n      <th>deaths_norm100k</th>\n      <th>recoveries_norm100k</th>\n      <th>testing_rate</th>\n      <th>Alabama_cases_norm100k</th>\n      <th>Alabama_deaths_norm100k</th>\n      <th>Alabama_recoveries_norm100k</th>\n      <th>Alabama_testing_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.708467</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>95.0</td>\n      <td>1.709144</td>\n      <td>0.009312</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.033137</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.102694</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.416934</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>144.0</td>\n      <td>2.977917</td>\n      <td>0.009312</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.198820</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.102694</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.416934</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>216.0</td>\n      <td>4.020499</td>\n      <td>0.018730</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.198820</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.410777</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.416934</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>317.0</td>\n      <td>5.521583</td>\n      <td>0.018730</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.101975</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.397640</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.616166</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.416934</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>476.0</td>\n      <td>7.974398</td>\n      <td>0.056613</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.122369</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 73 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "south_flattened_df = flatten_df(us_south_df, ['date'])\n",
    "print(south_flattened_df.columns)\n",
    "print(south_flattened_df.shape)\n",
    "south_flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "234\n",
      "(234, 576)\n",
      "[161140.0, 167301.0, 175455.0, 182320.0, 188388.0]\n",
      "(234, 576)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AVG_Alabama_cases_norm100k  AVG_Alabama_deaths_norm100k  \\\n",
       "0                   20.406804                     0.520070   \n",
       "1                   25.594039                     0.665188   \n",
       "2                   30.270412                     0.811426   \n",
       "3                   34.448357                     0.958561   \n",
       "4                   40.951613                     1.166589   \n",
       "\n",
       "   AVG_Alabama_recoveries_norm100k  AVG_Alabama_testing_rate  \\\n",
       "0                              0.0                596.316504   \n",
       "1                              0.0                628.927230   \n",
       "2                              0.0                658.363790   \n",
       "3                              0.0                683.167065   \n",
       "4                              0.0                715.172764   \n",
       "\n",
       "   AVG_Arkansas_cases_norm100k  AVG_Arkansas_deaths_norm100k  \\\n",
       "0                    10.130987                      0.194402   \n",
       "1                    13.597084                      0.267303   \n",
       "2                    17.173636                      0.349040   \n",
       "3                    20.904826                      0.430777   \n",
       "4                    24.744262                      0.514723   \n",
       "\n",
       "   AVG_Arkansas_recoveries_norm100k  AVG_Arkansas_testing_rate  \\\n",
       "0                          2.617798                 793.824604   \n",
       "1                          3.698053                 806.200554   \n",
       "2                          4.908647                 820.122772   \n",
       "3                          6.218650                 834.676502   \n",
       "4                          7.771656                 848.642035   \n",
       "\n",
       "   AVG_Delaware_cases_norm100k  AVG_Delaware_deaths_norm100k  ...  \\\n",
       "0                    37.545031                      0.814708  ...   \n",
       "1                    51.333451                      1.129637  ...   \n",
       "2                    65.498416                      1.506183  ...   \n",
       "3                    81.354414                      1.923806  ...   \n",
       "4                    98.702903                      2.382507  ...   \n",
       "\n",
       "   recoveries_norm100k_15  recoveries_norm100k_2  recoveries_norm100k_3  \\\n",
       "0              221.279697              32.153374              46.260321   \n",
       "1              244.093191              22.813495              54.966869   \n",
       "2              275.058888              30.965697              53.779191   \n",
       "3              290.943911              15.885023              46.850719   \n",
       "4              369.522208              78.578298              94.463320   \n",
       "\n",
       "   recoveries_norm100k_5  recoveries_norm100k_7  testing_rate_15  \\\n",
       "0             221.279697             221.279697      3377.430112   \n",
       "1             244.093191             244.093191      3377.430112   \n",
       "2             100.039512             275.058888      3377.430112   \n",
       "3             101.817588             290.943911      3377.430112   \n",
       "4             148.242511             194.502832      3377.430112   \n",
       "\n",
       "   testing_rate_2  testing_rate_3  testing_rate_5  testing_rate_7  \n",
       "0       69.766205      133.470299      967.718875     1451.775542  \n",
       "1       31.863555      101.629760      967.718875     1451.775542  \n",
       "2       40.528768       72.392323      205.862622     1451.775542  \n",
       "3       42.904183       83.432950      185.062711     1451.775542  \n",
       "4       52.354426       95.258609      167.650932      301.121230  \n",
       "\n",
       "[5 rows x 576 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AVG_Alabama_cases_norm100k</th>\n      <th>AVG_Alabama_deaths_norm100k</th>\n      <th>AVG_Alabama_recoveries_norm100k</th>\n      <th>AVG_Alabama_testing_rate</th>\n      <th>AVG_Arkansas_cases_norm100k</th>\n      <th>AVG_Arkansas_deaths_norm100k</th>\n      <th>AVG_Arkansas_recoveries_norm100k</th>\n      <th>AVG_Arkansas_testing_rate</th>\n      <th>AVG_Delaware_cases_norm100k</th>\n      <th>AVG_Delaware_deaths_norm100k</th>\n      <th>...</th>\n      <th>recoveries_norm100k_15</th>\n      <th>recoveries_norm100k_2</th>\n      <th>recoveries_norm100k_3</th>\n      <th>recoveries_norm100k_5</th>\n      <th>recoveries_norm100k_7</th>\n      <th>testing_rate_15</th>\n      <th>testing_rate_2</th>\n      <th>testing_rate_3</th>\n      <th>testing_rate_5</th>\n      <th>testing_rate_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20.406804</td>\n      <td>0.520070</td>\n      <td>0.0</td>\n      <td>596.316504</td>\n      <td>10.130987</td>\n      <td>0.194402</td>\n      <td>2.617798</td>\n      <td>793.824604</td>\n      <td>37.545031</td>\n      <td>0.814708</td>\n      <td>...</td>\n      <td>221.279697</td>\n      <td>32.153374</td>\n      <td>46.260321</td>\n      <td>221.279697</td>\n      <td>221.279697</td>\n      <td>3377.430112</td>\n      <td>69.766205</td>\n      <td>133.470299</td>\n      <td>967.718875</td>\n      <td>1451.775542</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25.594039</td>\n      <td>0.665188</td>\n      <td>0.0</td>\n      <td>628.927230</td>\n      <td>13.597084</td>\n      <td>0.267303</td>\n      <td>3.698053</td>\n      <td>806.200554</td>\n      <td>51.333451</td>\n      <td>1.129637</td>\n      <td>...</td>\n      <td>244.093191</td>\n      <td>22.813495</td>\n      <td>54.966869</td>\n      <td>244.093191</td>\n      <td>244.093191</td>\n      <td>3377.430112</td>\n      <td>31.863555</td>\n      <td>101.629760</td>\n      <td>967.718875</td>\n      <td>1451.775542</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.270412</td>\n      <td>0.811426</td>\n      <td>0.0</td>\n      <td>658.363790</td>\n      <td>17.173636</td>\n      <td>0.349040</td>\n      <td>4.908647</td>\n      <td>820.122772</td>\n      <td>65.498416</td>\n      <td>1.506183</td>\n      <td>...</td>\n      <td>275.058888</td>\n      <td>30.965697</td>\n      <td>53.779191</td>\n      <td>100.039512</td>\n      <td>275.058888</td>\n      <td>3377.430112</td>\n      <td>40.528768</td>\n      <td>72.392323</td>\n      <td>205.862622</td>\n      <td>1451.775542</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34.448357</td>\n      <td>0.958561</td>\n      <td>0.0</td>\n      <td>683.167065</td>\n      <td>20.904826</td>\n      <td>0.430777</td>\n      <td>6.218650</td>\n      <td>834.676502</td>\n      <td>81.354414</td>\n      <td>1.923806</td>\n      <td>...</td>\n      <td>290.943911</td>\n      <td>15.885023</td>\n      <td>46.850719</td>\n      <td>101.817588</td>\n      <td>290.943911</td>\n      <td>3377.430112</td>\n      <td>42.904183</td>\n      <td>83.432950</td>\n      <td>185.062711</td>\n      <td>1451.775542</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40.951613</td>\n      <td>1.166589</td>\n      <td>0.0</td>\n      <td>715.172764</td>\n      <td>24.744262</td>\n      <td>0.514723</td>\n      <td>7.771656</td>\n      <td>848.642035</td>\n      <td>98.702903</td>\n      <td>2.382507</td>\n      <td>...</td>\n      <td>369.522208</td>\n      <td>78.578298</td>\n      <td>94.463320</td>\n      <td>148.242511</td>\n      <td>194.502832</td>\n      <td>3377.430112</td>\n      <td>52.354426</td>\n      <td>95.258609</td>\n      <td>167.650932</td>\n      <td>301.121230</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 576 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "south_X, south_y = sliding_window(south_flattened_df, 15, 7)\n",
    "print(len(south_y))\n",
    "print(south_X.shape)\n",
    "print(south_y[:5])\n",
    "south_X = south_X.fillna(south_X.mean())\n",
    "print(south_X.shape)\n",
    "south_X.head()"
   ]
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "for column in south_X.columns:\n",
    "    if south_X[column].isnull().values.all():\n",
    "        print(column)\n",
    "south_X = south_X.drop(['Florida_recoveries_norm100k_15', 'Florida_recoveries_norm100k_7', 'Georgia_recoveries_norm100k_15', 'Georgia_recoveries_norm100k_7'], axis = 1)\n",
    "print(south_X.isnull().values.any())\n",
    "south_X_train, south_X_test, south_y_train, south_y_test = train_test_split(south_X, south_y, test_size = .25)\n",
    "south_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(south_X_train), columns = south_X_train.columns) + 1\n",
    "south_transformed_X_test = pd.DataFrame(Normalizer().transform(south_X_test), columns = south_X_test.columns) + 1\n",
    "\n",
    "selected_col_idx = SelectKBest(chi2, k = 15).fit(south_transformed_X_train, south_y_train).get_support(indices = True)\n",
    "south_selected_X_train = south_transformed_X_train.iloc[:, selected_col_idx]\n",
    "south_selected_X_test = south_transformed_X_test.iloc[:, selected_col_idx]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "south_new_selected_X_train = south_selected_X_train.drop(['Louisiana_testing_rate_15', 'Tennessee_testing_rate_15', 'Oklahoma_testing_rate_15', 'testing_rate_15', 'Arkansas_testing_rate_15', 'Delaware_testing_rate_15', 'District of Columbia_testing_rate_15'], axis = 1)\n",
    "#northeast_selected_X_test = northeast_selected_X_test.drop(['New York_testing_rate_15', 'Rhode Island_testing_rate_15', 'Max_cases_norm100k', 'AVG_cases_norm100k', 'Max_Massachusetts_testing_rate'], axis = 1)\n",
    "corr_matrix = south_new_selected_X_train.corr('spearman')\n",
    "for row_idx, row in corr_matrix.iterrows():\n",
    "    for col_idx, cor in row.iteritems():\n",
    "        if col_idx != row_idx and cor > .8:\n",
    "            print(str(row_idx) + ' ' + str(col_idx) + ' = ' + str(corr_matrix.loc[row_idx, col_idx]))\n",
    "print(south_new_selected_X_train.columns)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLUMNS = ['Florida_testing_rate_15', 'Kentucky_testing_rate_15', 'Maryland_testing_rate_15', 'Min_District of Columbia_testing_rate', 'Min_cases_norm100k', 'North Carolina_testing_rate_15', 'West Virginia_testing_rate_15', 'cases_norm100k_15']\n",
    "south_X_train, south_X_test, south_y_train, south_y_test = train_test_split(south_X, south_y, test_size = .25)\n",
    "south_selected_X_train = south_X_train[CHOSEN_COLUMNS]\n",
    "south_selected_X_test = south_X_test[CHOSEN_COLUMNS]\n",
    "south_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(south_selected_X_train), columns = south_selected_X_train.columns)\n",
    "south_transformed_X_test = pd.DataFrame(Normalizer().transform(south_selected_X_test), columns = south_selected_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Florida_testing_rate_15': 1758818.5367659072, 'Kentucky_testing_rate_15': 4278223.350714569, 'Maryland_testing_rate_15': 1539257.0196117922, 'Min_District of Columbia_testing_rate': 16844518.012136456, 'Min_cases_norm100k': -7494493.273423731, 'North Carolina_testing_rate_15': -7081328.155664981, 'West Virginia_testing_rate_15': 1626994.5245874093, 'cases_norm100k_15': 2926973.9170898455}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression().fit(south_transformed_X_train, south_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(south_transformed_X_train.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.94\nThe Mean Absolute Error: 260359.23 cases\nThe Median Absolute Error: 164525.35 cases\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(south_transformed_X_test)\n",
    "print(\"The Explained Variance: %.2f\" % reg.score(south_transformed_X_test, south_y_test))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(south_y_test, y_pred))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(south_y_test, y_pred))"
   ]
  },
  {
   "source": [
    "# Midwest Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Illinois_cases_norm100k', 'Illinois_deaths_norm100k',\n       'Illinois_recoveries_norm100k', 'Illinois_testing_rate', 'cases',\n       'cases_norm100k', 'deaths_norm100k', 'recoveries_norm100k',\n       'testing_rate', 'Indiana_cases_norm100k', 'Indiana_deaths_norm100k',\n       'Indiana_recoveries_norm100k', 'Indiana_testing_rate',\n       'Iowa_cases_norm100k', 'Iowa_deaths_norm100k',\n       'Iowa_recoveries_norm100k', 'Iowa_testing_rate',\n       'Kansas_cases_norm100k', 'Kansas_deaths_norm100k',\n       'Kansas_recoveries_norm100k', 'Kansas_testing_rate',\n       'Michigan_cases_norm100k', 'Michigan_deaths_norm100k',\n       'Michigan_recoveries_norm100k', 'Michigan_testing_rate',\n       'Minnesota_cases_norm100k', 'Minnesota_deaths_norm100k',\n       'Minnesota_recoveries_norm100k', 'Minnesota_testing_rate',\n       'Missouri_cases_norm100k', 'Missouri_deaths_norm100k',\n       'Missouri_recoveries_norm100k', 'Missouri_testing_rate',\n       'Nebraska_cases_norm100k', 'Nebraska_deaths_norm100k',\n       'Nebraska_recoveries_norm100k', 'Nebraska_testing_rate',\n       'North Dakota_cases_norm100k', 'North Dakota_deaths_norm100k',\n       'North Dakota_recoveries_norm100k', 'North Dakota_testing_rate',\n       'Ohio_cases_norm100k', 'Ohio_deaths_norm100k',\n       'Ohio_recoveries_norm100k', 'Ohio_testing_rate',\n       'South Dakota_cases_norm100k', 'South Dakota_deaths_norm100k',\n       'South Dakota_recoveries_norm100k', 'South Dakota_testing_rate',\n       'Wisconsin_cases_norm100k', 'Wisconsin_deaths_norm100k',\n       'Wisconsin_recoveries_norm100k', 'Wisconsin_testing_rate'],\n      dtype='object')\n(262, 53)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Illinois_cases_norm100k  Illinois_deaths_norm100k  \\\n",
       "0                 0.007892                       NaN   \n",
       "1                 0.007892                       NaN   \n",
       "2                 0.007892                       NaN   \n",
       "3                 0.007892                       NaN   \n",
       "4                 0.007892                       NaN   \n",
       "\n",
       "   Illinois_recoveries_norm100k  Illinois_testing_rate  cases  cases_norm100k  \\\n",
       "0                           NaN                    NaN    1.0        0.007892   \n",
       "1                           NaN                    NaN    1.0        0.007892   \n",
       "2                           NaN                    NaN    1.0        0.007892   \n",
       "3                           NaN                    NaN    1.0        0.007892   \n",
       "4                           NaN                    NaN    1.0        0.007892   \n",
       "\n",
       "   deaths_norm100k  recoveries_norm100k  testing_rate  Indiana_cases_norm100k  \\\n",
       "0              0.0                  0.0           NaN                     NaN   \n",
       "1              0.0                  0.0           NaN                     NaN   \n",
       "2              0.0                  0.0           NaN                     NaN   \n",
       "3              0.0                  0.0           NaN                     NaN   \n",
       "4              0.0                  0.0           NaN                     NaN   \n",
       "\n",
       "   ...  Ohio_recoveries_norm100k  Ohio_testing_rate  \\\n",
       "0  ...                       NaN                NaN   \n",
       "1  ...                       NaN                NaN   \n",
       "2  ...                       NaN                NaN   \n",
       "3  ...                       NaN                NaN   \n",
       "4  ...                       NaN                NaN   \n",
       "\n",
       "   South Dakota_cases_norm100k  South Dakota_deaths_norm100k  \\\n",
       "0                          NaN                           NaN   \n",
       "1                          NaN                           NaN   \n",
       "2                          NaN                           NaN   \n",
       "3                          NaN                           NaN   \n",
       "4                          NaN                           NaN   \n",
       "\n",
       "   South Dakota_recoveries_norm100k  South Dakota_testing_rate  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "\n",
       "   Wisconsin_cases_norm100k  Wisconsin_deaths_norm100k  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "   Wisconsin_recoveries_norm100k  Wisconsin_testing_rate  \n",
       "0                            NaN                     NaN  \n",
       "1                            NaN                     NaN  \n",
       "2                            NaN                     NaN  \n",
       "3                            NaN                     NaN  \n",
       "4                            NaN                     NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Illinois_cases_norm100k</th>\n      <th>Illinois_deaths_norm100k</th>\n      <th>Illinois_recoveries_norm100k</th>\n      <th>Illinois_testing_rate</th>\n      <th>cases</th>\n      <th>cases_norm100k</th>\n      <th>deaths_norm100k</th>\n      <th>recoveries_norm100k</th>\n      <th>testing_rate</th>\n      <th>Indiana_cases_norm100k</th>\n      <th>...</th>\n      <th>Ohio_recoveries_norm100k</th>\n      <th>Ohio_testing_rate</th>\n      <th>South Dakota_cases_norm100k</th>\n      <th>South Dakota_deaths_norm100k</th>\n      <th>South Dakota_recoveries_norm100k</th>\n      <th>South Dakota_testing_rate</th>\n      <th>Wisconsin_cases_norm100k</th>\n      <th>Wisconsin_deaths_norm100k</th>\n      <th>Wisconsin_recoveries_norm100k</th>\n      <th>Wisconsin_testing_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007892</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.007892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.007892</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.007892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.007892</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.007892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.007892</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.007892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.007892</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.007892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "midwest_flattened_df = flatten_df(us_midwest_df, ['date'])\n",
    "print(midwest_flattened_df.columns)\n",
    "print(midwest_flattened_df.shape)\n",
    "midwest_flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "241\n",
      "(241, 416)\n",
      "[81623.0, 85660.0, 89769.0, 95288.0, 100454.0]\n",
      "(241, 416)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AVG_Illinois_cases_norm100k  AVG_Illinois_deaths_norm100k  \\\n",
       "0                     0.287252                      0.000986   \n",
       "1                     0.371954                      0.001754   \n",
       "2                     0.593443                      0.004735   \n",
       "3                     0.900686                      0.007892   \n",
       "4                     1.296315                      0.011180   \n",
       "\n",
       "   AVG_Illinois_recoveries_norm100k  AVG_Illinois_testing_rate  \\\n",
       "0                          0.015783                27303.66553   \n",
       "1                          0.014029                27303.66553   \n",
       "2                          0.012626                27303.66553   \n",
       "3                          0.011479                27303.66553   \n",
       "4                          0.010522                27303.66553   \n",
       "\n",
       "   AVG_Indiana_cases_norm100k  AVG_Indiana_deaths_norm100k  \\\n",
       "0                    0.248804                     0.005570   \n",
       "1                    0.285526                     0.008252   \n",
       "2                    0.346097                     0.010398   \n",
       "3                    0.430764                     0.012153   \n",
       "4                    0.553309                     0.016092   \n",
       "\n",
       "   AVG_Indiana_recoveries_norm100k  AVG_Indiana_testing_rate  \\\n",
       "0                              0.0              16219.172119   \n",
       "1                              0.0              16219.172119   \n",
       "2                              0.0              16219.172119   \n",
       "3                              0.0              16219.172119   \n",
       "4                              0.0              16219.172119   \n",
       "\n",
       "   AVG_Iowa_cases_norm100k  AVG_Iowa_deaths_norm100k  ...  \\\n",
       "0                 0.534853                       0.0  ...   \n",
       "1                 0.577554                       0.0  ...   \n",
       "2                 0.659256                       0.0  ...   \n",
       "3                 0.728985                       0.0  ...   \n",
       "4                 0.847842                       0.0  ...   \n",
       "\n",
       "   recoveries_norm100k_15  recoveries_norm100k_2  recoveries_norm100k_3  \\\n",
       "0                0.032958               0.000000               0.000000   \n",
       "1                0.000000              -0.032958              -0.032958   \n",
       "2                0.000000               0.000000              -0.032958   \n",
       "3                0.000000               0.000000               0.000000   \n",
       "4                0.000000               0.000000               0.000000   \n",
       "\n",
       "   recoveries_norm100k_5  recoveries_norm100k_7  testing_rate_15  \\\n",
       "0               0.000000               0.000000      3891.381491   \n",
       "1              -0.032958              -0.032958      3891.381491   \n",
       "2              -0.032958              -0.032958      3891.381491   \n",
       "3              -0.032958              -0.032958      3891.381491   \n",
       "4              -0.032958              -0.032958      3891.381491   \n",
       "\n",
       "   testing_rate_2  testing_rate_3  testing_rate_5  testing_rate_7  \n",
       "0      278.495367      556.546182     1113.613988     1671.497105  \n",
       "1      278.495367      556.546182     1113.613988     1671.497105  \n",
       "2      278.495367      556.546182     1113.613988     1671.497105  \n",
       "3      278.495367      556.546182     1113.613988     1671.497105  \n",
       "4      278.495367      556.546182     1113.613988     1671.497105  \n",
       "\n",
       "[5 rows x 416 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AVG_Illinois_cases_norm100k</th>\n      <th>AVG_Illinois_deaths_norm100k</th>\n      <th>AVG_Illinois_recoveries_norm100k</th>\n      <th>AVG_Illinois_testing_rate</th>\n      <th>AVG_Indiana_cases_norm100k</th>\n      <th>AVG_Indiana_deaths_norm100k</th>\n      <th>AVG_Indiana_recoveries_norm100k</th>\n      <th>AVG_Indiana_testing_rate</th>\n      <th>AVG_Iowa_cases_norm100k</th>\n      <th>AVG_Iowa_deaths_norm100k</th>\n      <th>...</th>\n      <th>recoveries_norm100k_15</th>\n      <th>recoveries_norm100k_2</th>\n      <th>recoveries_norm100k_3</th>\n      <th>recoveries_norm100k_5</th>\n      <th>recoveries_norm100k_7</th>\n      <th>testing_rate_15</th>\n      <th>testing_rate_2</th>\n      <th>testing_rate_3</th>\n      <th>testing_rate_5</th>\n      <th>testing_rate_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.287252</td>\n      <td>0.000986</td>\n      <td>0.015783</td>\n      <td>27303.66553</td>\n      <td>0.248804</td>\n      <td>0.005570</td>\n      <td>0.0</td>\n      <td>16219.172119</td>\n      <td>0.534853</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.032958</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3891.381491</td>\n      <td>278.495367</td>\n      <td>556.546182</td>\n      <td>1113.613988</td>\n      <td>1671.497105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.371954</td>\n      <td>0.001754</td>\n      <td>0.014029</td>\n      <td>27303.66553</td>\n      <td>0.285526</td>\n      <td>0.008252</td>\n      <td>0.0</td>\n      <td>16219.172119</td>\n      <td>0.577554</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>3891.381491</td>\n      <td>278.495367</td>\n      <td>556.546182</td>\n      <td>1113.613988</td>\n      <td>1671.497105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.593443</td>\n      <td>0.004735</td>\n      <td>0.012626</td>\n      <td>27303.66553</td>\n      <td>0.346097</td>\n      <td>0.010398</td>\n      <td>0.0</td>\n      <td>16219.172119</td>\n      <td>0.659256</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>3891.381491</td>\n      <td>278.495367</td>\n      <td>556.546182</td>\n      <td>1113.613988</td>\n      <td>1671.497105</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.900686</td>\n      <td>0.007892</td>\n      <td>0.011479</td>\n      <td>27303.66553</td>\n      <td>0.430764</td>\n      <td>0.012153</td>\n      <td>0.0</td>\n      <td>16219.172119</td>\n      <td>0.728985</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>3891.381491</td>\n      <td>278.495367</td>\n      <td>556.546182</td>\n      <td>1113.613988</td>\n      <td>1671.497105</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.296315</td>\n      <td>0.011180</td>\n      <td>0.010522</td>\n      <td>27303.66553</td>\n      <td>0.553309</td>\n      <td>0.016092</td>\n      <td>0.0</td>\n      <td>16219.172119</td>\n      <td>0.847842</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.032958</td>\n      <td>-0.032958</td>\n      <td>3891.381491</td>\n      <td>278.495367</td>\n      <td>556.546182</td>\n      <td>1113.613988</td>\n      <td>1671.497105</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 416 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "midwest_X, midwest_y = sliding_window(midwest_flattened_df, 15, 7)\n",
    "print(len(midwest_y))\n",
    "print(midwest_X.shape)\n",
    "print(midwest_y[:5])\n",
    "midwest_X = midwest_X.fillna(midwest_X.mean())\n",
    "print(midwest_X.shape)\n",
    "midwest_X.head()"
   ]
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "for column in midwest_X.columns:\n",
    "    if midwest_X[column].isnull().values.all():\n",
    "        print(column)\n",
    "midwest_X = midwest_X.drop(['Illinois_recoveries_norm100k_15', 'Missouri_recoveries_norm100k_15'], axis = 1)\n",
    "print(midwest_X.isnull().values.any())\n",
    "midwest_X_train, midwest_X_test, midwest_y_train, midwest_y_test = train_test_split(midwest_X, midwest_y, test_size = .25)\n",
    "midwest_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(midwest_X_train), columns = midwest_X_train.columns) + 1\n",
    "midwest_transformed_X_test = pd.DataFrame(Normalizer().transform(midwest_X_test), columns = midwest_X_test.columns) + 1\n",
    "\n",
    "selected_col_idx = SelectKBest(chi2, k = 15).fit(midwest_transformed_X_train, midwest_y_train).get_support(indices = True)\n",
    "midwest_selected_X_train = midwest_transformed_X_train.iloc[:, selected_col_idx]\n",
    "midwest_selected_X_test = midwest_transformed_X_test.iloc[:, selected_col_idx]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "midwest_new_selected_X_train = midwest_selected_X_train.drop(['Michigan_testing_rate_15', 'AVG_North Dakota_testing_rate', 'Illinois_testing_rate_15', 'North Dakota_testing_rate_15', 'Nebraska_testing_rate_15'], axis = 1)\n",
    "#northeast_selected_X_test = northeast_selected_X_test.drop(['New York_testing_rate_15', 'Rhode Island_testing_rate_15', 'Max_cases_norm100k', 'AVG_cases_norm100k', 'Max_Massachusetts_testing_rate'], axis = 1)\n",
    "corr_matrix = midwest_new_selected_X_train.corr('spearman')\n",
    "for row_idx, row in corr_matrix.iterrows():\n",
    "    for col_idx, cor in row.iteritems():\n",
    "        if col_idx != row_idx and cor > .8:\n",
    "            print(str(row_idx) + ' ' + str(col_idx) + ' = ' + str(corr_matrix.loc[row_idx, col_idx]))\n",
    "#print(corr_matrix['Nebraska_testing_rate_15'].sum())\n",
    "#print(corr_matrix['Wisconsin_testing_rate_15'].sum())\n",
    "print(midwest_new_selected_X_train.columns)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLUMNS = ['Indiana_testing_rate_15', 'Max_North Dakota_testing_rate', 'Min_Illinois_testing_rate', 'Min_North Dakota_testing_rate', 'Minnesota_testing_rate_15', 'Missouri_testing_rate_15', 'North Dakota_testing_rate_7', 'Ohio_testing_rate_15', 'Wisconsin_testing_rate_15', 'testing_rate_15']\n",
    "midwest_X_train, midwest_X_test, midwest_y_train, midwest_y_test = train_test_split(midwest_X, midwest_y, test_size = .25)\n",
    "midwest_selected_X_train = midwest_X_train[CHOSEN_COLUMNS]\n",
    "midwest_selected_X_test = midwest_X_test[CHOSEN_COLUMNS]\n",
    "midwest_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(midwest_selected_X_train), columns = midwest_selected_X_train.columns)\n",
    "midwest_transformed_X_test = pd.DataFrame(Normalizer().transform(midwest_selected_X_test), columns = midwest_selected_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Indiana_testing_rate_15': -778411.1311789437, 'Max_North Dakota_testing_rate': -10565200.074391007, 'Min_Illinois_testing_rate': -6484411.025975477, 'Min_North Dakota_testing_rate': -4210772.707265199, 'Minnesota_testing_rate_15': -3479016.679890118, 'Missouri_testing_rate_15': -8634741.309743261, 'North Dakota_testing_rate_7': -4227511.904817755, 'Ohio_testing_rate_15': -23865066.32276553, 'Wisconsin_testing_rate_15': 102298.72724636551, 'testing_rate_15': 1117876.1483829645}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression().fit(midwest_transformed_X_train, midwest_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(midwest_transformed_X_train.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.67\nThe Mean Absolute Error: 504090.82 cases\nThe Median Absolute Error: 276273.36 cases\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(midwest_transformed_X_test)\n",
    "print(\"The Explained Variance: %.2f\" % reg.score(midwest_transformed_X_test, midwest_y_test))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(midwest_y_test, y_pred))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(midwest_y_test, y_pred))"
   ]
  },
  {
   "source": [
    "# West Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Washington_cases_norm100k', 'Washington_deaths_norm100k',\n       'Washington_recoveries_norm100k', 'Washington_testing_rate', 'cases',\n       'cases_norm100k', 'deaths_norm100k', 'recoveries_norm100k',\n       'testing_rate', 'Arizona_cases_norm100k', 'Arizona_deaths_norm100k',\n       'Arizona_recoveries_norm100k', 'Arizona_testing_rate',\n       'California_cases_norm100k', 'California_deaths_norm100k',\n       'California_recoveries_norm100k', 'California_testing_rate',\n       'Alaska_cases_norm100k', 'Alaska_deaths_norm100k',\n       'Alaska_recoveries_norm100k', 'Alaska_testing_rate',\n       'Colorado_cases_norm100k', 'Colorado_deaths_norm100k',\n       'Colorado_recoveries_norm100k', 'Colorado_testing_rate',\n       'Hawaii_cases_norm100k', 'Hawaii_deaths_norm100k',\n       'Hawaii_recoveries_norm100k', 'Hawaii_testing_rate',\n       'Idaho_cases_norm100k', 'Idaho_deaths_norm100k',\n       'Idaho_recoveries_norm100k', 'Idaho_testing_rate',\n       'Montana_cases_norm100k', 'Montana_deaths_norm100k',\n       'Montana_recoveries_norm100k', 'Montana_testing_rate',\n       'Nevada_cases_norm100k', 'Nevada_deaths_norm100k',\n       'Nevada_recoveries_norm100k', 'Nevada_testing_rate',\n       'New Mexico_cases_norm100k', 'New Mexico_deaths_norm100k',\n       'New Mexico_recoveries_norm100k', 'New Mexico_testing_rate',\n       'Oregon_cases_norm100k', 'Oregon_deaths_norm100k',\n       'Oregon_recoveries_norm100k', 'Oregon_testing_rate',\n       'Utah_cases_norm100k', 'Utah_deaths_norm100k',\n       'Utah_recoveries_norm100k', 'Utah_testing_rate',\n       'Wyoming_cases_norm100k', 'Wyoming_deaths_norm100k',\n       'Wyoming_recoveries_norm100k', 'Wyoming_testing_rate'],\n      dtype='object')\n(265, 57)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Washington_cases_norm100k  Washington_deaths_norm100k  \\\n",
       "0                   0.013132                         NaN   \n",
       "1                   0.013132                         NaN   \n",
       "2                   0.013132                         NaN   \n",
       "3                   0.013132                         NaN   \n",
       "4                   0.013132                         NaN   \n",
       "\n",
       "   Washington_recoveries_norm100k  Washington_testing_rate  cases  \\\n",
       "0                             NaN                      NaN    1.0   \n",
       "1                             NaN                      NaN    1.0   \n",
       "2                             NaN                      NaN    1.0   \n",
       "3                             NaN                      NaN    1.0   \n",
       "4                             NaN                      NaN    4.0   \n",
       "\n",
       "   cases_norm100k  deaths_norm100k  recoveries_norm100k  testing_rate  \\\n",
       "0        0.013132              0.0                  0.0           NaN   \n",
       "1        0.013132              0.0                  0.0           NaN   \n",
       "2        0.013132              0.0                  0.0           NaN   \n",
       "3        0.013132              0.0                  0.0           NaN   \n",
       "4        0.031933              0.0                  0.0           NaN   \n",
       "\n",
       "   Arizona_cases_norm100k  ...  Oregon_recoveries_norm100k  \\\n",
       "0                     NaN  ...                         NaN   \n",
       "1                     NaN  ...                         NaN   \n",
       "2                     NaN  ...                         NaN   \n",
       "3                     NaN  ...                         NaN   \n",
       "4                0.013739  ...                         NaN   \n",
       "\n",
       "   Oregon_testing_rate  Utah_cases_norm100k  Utah_deaths_norm100k  \\\n",
       "0                  NaN                  NaN                   NaN   \n",
       "1                  NaN                  NaN                   NaN   \n",
       "2                  NaN                  NaN                   NaN   \n",
       "3                  NaN                  NaN                   NaN   \n",
       "4                  NaN                  NaN                   NaN   \n",
       "\n",
       "   Utah_recoveries_norm100k  Utah_testing_rate  Wyoming_cases_norm100k  \\\n",
       "0                       NaN                NaN                     NaN   \n",
       "1                       NaN                NaN                     NaN   \n",
       "2                       NaN                NaN                     NaN   \n",
       "3                       NaN                NaN                     NaN   \n",
       "4                       NaN                NaN                     NaN   \n",
       "\n",
       "   Wyoming_deaths_norm100k  Wyoming_recoveries_norm100k  Wyoming_testing_rate  \n",
       "0                      NaN                          NaN                   NaN  \n",
       "1                      NaN                          NaN                   NaN  \n",
       "2                      NaN                          NaN                   NaN  \n",
       "3                      NaN                          NaN                   NaN  \n",
       "4                      NaN                          NaN                   NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Washington_cases_norm100k</th>\n      <th>Washington_deaths_norm100k</th>\n      <th>Washington_recoveries_norm100k</th>\n      <th>Washington_testing_rate</th>\n      <th>cases</th>\n      <th>cases_norm100k</th>\n      <th>deaths_norm100k</th>\n      <th>recoveries_norm100k</th>\n      <th>testing_rate</th>\n      <th>Arizona_cases_norm100k</th>\n      <th>...</th>\n      <th>Oregon_recoveries_norm100k</th>\n      <th>Oregon_testing_rate</th>\n      <th>Utah_cases_norm100k</th>\n      <th>Utah_deaths_norm100k</th>\n      <th>Utah_recoveries_norm100k</th>\n      <th>Utah_testing_rate</th>\n      <th>Wyoming_cases_norm100k</th>\n      <th>Wyoming_deaths_norm100k</th>\n      <th>Wyoming_recoveries_norm100k</th>\n      <th>Wyoming_testing_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.013132</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.013132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.013132</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.013132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.013132</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.013132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.013132</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.013132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.013132</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.031933</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.013739</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "west_flattened_df = flatten_df(us_west_df, ['date'])\n",
    "print(west_flattened_df.columns)\n",
    "print(west_flattened_df.shape)\n",
    "west_flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "244\n",
      "(244, 448)\n",
      "[4251.0, 54999.0, 57037.0, 59384.0, 61435.0]\n",
      "(244, 448)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AVG_Alaska_cases_norm100k  AVG_Alaska_deaths_norm100k  \\\n",
       "0                   0.034174                         0.0   \n",
       "1                   0.054679                         0.0   \n",
       "2                   0.068348                         0.0   \n",
       "3                   0.117169                         0.0   \n",
       "4                   0.205045                         0.0   \n",
       "\n",
       "   AVG_Alaska_recoveries_norm100k  AVG_Alaska_testing_rate  \\\n",
       "0                             0.0             39724.427308   \n",
       "1                             0.0             39724.427308   \n",
       "2                             0.0             39724.427308   \n",
       "3                             0.0             39724.427308   \n",
       "4                             0.0             39724.427308   \n",
       "\n",
       "   AVG_Arizona_cases_norm100k  AVG_Arizona_deaths_norm100k  \\\n",
       "0                    0.063698                          0.0   \n",
       "1                    0.073273                          0.0   \n",
       "2                    0.086659                          0.0   \n",
       "3                    0.100096                          0.0   \n",
       "4                    0.118153                          0.0   \n",
       "\n",
       "   AVG_Arizona_recoveries_norm100k  AVG_Arizona_testing_rate  \\\n",
       "0                         0.013739              12497.697306   \n",
       "1                         0.013739              12497.697306   \n",
       "2                         0.013739              12497.697306   \n",
       "3                         0.013739              12497.697306   \n",
       "4                         0.012212              12497.697306   \n",
       "\n",
       "   AVG_California_cases_norm100k  AVG_California_deaths_norm100k  ...  \\\n",
       "0                       0.270572                        0.009111  ...   \n",
       "1                       0.337870                        0.010123  ...   \n",
       "2                       0.420318                        0.011208  ...   \n",
       "3                       0.516477                        0.013603  ...   \n",
       "4                       0.608757                        0.015748  ...   \n",
       "\n",
       "   recoveries_norm100k_15  recoveries_norm100k_2  recoveries_norm100k_3  \\\n",
       "0                0.042056               0.000000               0.000000   \n",
       "1                0.042056               0.000000               0.000000   \n",
       "2                0.042056               0.000000               0.000000   \n",
       "3                0.042056               0.000000               0.000000   \n",
       "4                0.000000              -0.042056              -0.042056   \n",
       "\n",
       "   recoveries_norm100k_5  recoveries_norm100k_7  testing_rate_15  \\\n",
       "0               0.010123               0.042056      3324.610862   \n",
       "1               0.010123               0.042056      3324.610862   \n",
       "2               0.000000               0.010123      3324.610862   \n",
       "3               0.000000               0.010123      3324.610862   \n",
       "4              -0.042056              -0.042056      3324.610862   \n",
       "\n",
       "   testing_rate_2  testing_rate_3  testing_rate_5  testing_rate_7  \n",
       "0      242.814386      485.119506       972.39034     1458.212626  \n",
       "1      242.814386      485.119506       972.39034     1458.212626  \n",
       "2      242.814386      485.119506       972.39034     1458.212626  \n",
       "3      242.814386      485.119506       972.39034     1458.212626  \n",
       "4      242.814386      485.119506       972.39034     1458.212626  \n",
       "\n",
       "[5 rows x 448 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AVG_Alaska_cases_norm100k</th>\n      <th>AVG_Alaska_deaths_norm100k</th>\n      <th>AVG_Alaska_recoveries_norm100k</th>\n      <th>AVG_Alaska_testing_rate</th>\n      <th>AVG_Arizona_cases_norm100k</th>\n      <th>AVG_Arizona_deaths_norm100k</th>\n      <th>AVG_Arizona_recoveries_norm100k</th>\n      <th>AVG_Arizona_testing_rate</th>\n      <th>AVG_California_cases_norm100k</th>\n      <th>AVG_California_deaths_norm100k</th>\n      <th>...</th>\n      <th>recoveries_norm100k_15</th>\n      <th>recoveries_norm100k_2</th>\n      <th>recoveries_norm100k_3</th>\n      <th>recoveries_norm100k_5</th>\n      <th>recoveries_norm100k_7</th>\n      <th>testing_rate_15</th>\n      <th>testing_rate_2</th>\n      <th>testing_rate_3</th>\n      <th>testing_rate_5</th>\n      <th>testing_rate_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034174</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39724.427308</td>\n      <td>0.063698</td>\n      <td>0.0</td>\n      <td>0.013739</td>\n      <td>12497.697306</td>\n      <td>0.270572</td>\n      <td>0.009111</td>\n      <td>...</td>\n      <td>0.042056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010123</td>\n      <td>0.042056</td>\n      <td>3324.610862</td>\n      <td>242.814386</td>\n      <td>485.119506</td>\n      <td>972.39034</td>\n      <td>1458.212626</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.054679</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39724.427308</td>\n      <td>0.073273</td>\n      <td>0.0</td>\n      <td>0.013739</td>\n      <td>12497.697306</td>\n      <td>0.337870</td>\n      <td>0.010123</td>\n      <td>...</td>\n      <td>0.042056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010123</td>\n      <td>0.042056</td>\n      <td>3324.610862</td>\n      <td>242.814386</td>\n      <td>485.119506</td>\n      <td>972.39034</td>\n      <td>1458.212626</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.068348</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39724.427308</td>\n      <td>0.086659</td>\n      <td>0.0</td>\n      <td>0.013739</td>\n      <td>12497.697306</td>\n      <td>0.420318</td>\n      <td>0.011208</td>\n      <td>...</td>\n      <td>0.042056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010123</td>\n      <td>3324.610862</td>\n      <td>242.814386</td>\n      <td>485.119506</td>\n      <td>972.39034</td>\n      <td>1458.212626</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117169</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39724.427308</td>\n      <td>0.100096</td>\n      <td>0.0</td>\n      <td>0.013739</td>\n      <td>12497.697306</td>\n      <td>0.516477</td>\n      <td>0.013603</td>\n      <td>...</td>\n      <td>0.042056</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010123</td>\n      <td>3324.610862</td>\n      <td>242.814386</td>\n      <td>485.119506</td>\n      <td>972.39034</td>\n      <td>1458.212626</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.205045</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39724.427308</td>\n      <td>0.118153</td>\n      <td>0.0</td>\n      <td>0.012212</td>\n      <td>12497.697306</td>\n      <td>0.608757</td>\n      <td>0.015748</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-0.042056</td>\n      <td>-0.042056</td>\n      <td>-0.042056</td>\n      <td>-0.042056</td>\n      <td>3324.610862</td>\n      <td>242.814386</td>\n      <td>485.119506</td>\n      <td>972.39034</td>\n      <td>1458.212626</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 448 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "west_X, west_y = sliding_window(west_flattened_df, 15, 7)\n",
    "print(len(west_y))\n",
    "print(west_X.shape)\n",
    "print(west_y[:5])\n",
    "west_X = west_X.fillna(west_X.mean())\n",
    "print(west_X.shape)\n",
    "west_X.head()"
   ]
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "for column in west_X.columns:\n",
    "    if west_X[column].isnull().values.all():\n",
    "        print(column)\n",
    "west_X = west_X.drop(['California_recoveries_norm100k_15', 'Washington_recoveries_norm100k_15'], axis = 1)\n",
    "print(west_X.isnull().values.any())\n",
    "west_X_train, west_X_test, west_y_train, west_y_test = train_test_split(west_X, west_y, test_size = .25)\n",
    "west_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(west_X_train), columns = west_X_train.columns) + 1\n",
    "west_transformed_X_test = pd.DataFrame(Normalizer().transform(west_X_test), columns = west_X_test.columns) + 1\n",
    "\n",
    "selected_col_idx = SelectKBest(chi2, k = 15).fit(west_transformed_X_train, west_y_train).get_support(indices = True)\n",
    "west_selected_X_train = west_transformed_X_train.iloc[:, selected_col_idx]\n",
    "west_selected_X_test = west_transformed_X_test.iloc[:, selected_col_idx]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "west_new_selected_X_train = west_selected_X_train.drop(['testing_rate_15', 'Min_Alaska_testing_rate', 'New Mexico_testing_rate_15', 'Utah_testing_rate_15', 'AVG_Alaska_testing_rate'], axis = 1)\n",
    "#northeast_selected_X_test = northeast_selected_X_test.drop(['New York_testing_rate_15', 'Rhode Island_testing_rate_15', 'Max_cases_norm100k', 'AVG_cases_norm100k', 'Max_Massachusetts_testing_rate'], axis = 1)\n",
    "corr_matrix = west_new_selected_X_train.corr('spearman')\n",
    "for row_idx, row in corr_matrix.iterrows():\n",
    "    for col_idx, cor in row.iteritems():\n",
    "        if col_idx != row_idx and cor > .8:\n",
    "            print(str(row_idx) + ' ' + str(col_idx) + ' = ' + str(corr_matrix.loc[row_idx, col_idx]))\n",
    "#print(corr_matrix['AVG_Alaska_testing_rate'].sum())\n",
    "#print(corr_matrix['Max_Alaska_testing_rate'].sum())\n",
    "#print(corr_matrix['Nevada_testing_rate_15'].sum())\n",
    "#print(corr_matrix['Utah_testing_rate_15'].sum())\n",
    "print(west_new_selected_X_train.columns)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLUMNS = ['Alaska_testing_rate_15', 'California_testing_rate_15', 'Colorado_testing_rate_15', 'Max_Alaska_testing_rate', 'Max_New Mexico_testing_rate', 'Max_Utah_testing_rate', 'Min_California_testing_rate', 'Montana_testing_rate_15', 'Nevada_testing_rate_15', 'Wyoming_testing_rate_15']\n",
    "west_X_train, west_X_test, west_y_train, west_y_test = train_test_split(west_X, west_y, test_size = .25)\n",
    "west_selected_X_train = west_X_train[CHOSEN_COLUMNS]\n",
    "west_selected_X_test = west_X_test[CHOSEN_COLUMNS]\n",
    "west_transformed_X_train = pd.DataFrame(Normalizer().fit_transform(west_selected_X_train), columns = west_selected_X_train.columns)\n",
    "west_transformed_X_test = pd.DataFrame(Normalizer().transform(west_selected_X_test), columns = west_selected_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Alaska_testing_rate_15': -2522109.754428714, 'California_testing_rate_15': -1570351.792930963, 'Colorado_testing_rate_15': -1277950.7758332458, 'Max_Alaska_testing_rate': 6118860.368100989, 'Max_New Mexico_testing_rate': -4203721.770991845, 'Max_Utah_testing_rate': -893751.2193031098, 'Min_California_testing_rate': -3995361.8301948756, 'Montana_testing_rate_15': 2214569.5414572023, 'Nevada_testing_rate_15': 2444576.104345589, 'Wyoming_testing_rate_15': 1533936.2818068794}\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression().fit(west_transformed_X_train, west_y_train)\n",
    "coef = {}\n",
    "for idx, name in enumerate(west_transformed_X_train.columns):\n",
    "    coef[name] = reg.coef_[idx]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Explained Variance: 0.81\nThe Mean Absolute Error: 155487.98 cases\nThe Median Absolute Error: 91248.15 cases\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(west_transformed_X_test)\n",
    "print(\"The Explained Variance: %.2f\" % reg.score(west_transformed_X_test, west_y_test))\n",
    "print(\"The Mean Absolute Error: %.2f cases\" % mean_absolute_error(west_y_test, y_pred))\n",
    "print(\"The Median Absolute Error: %.2f cases\" % median_absolute_error(west_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}